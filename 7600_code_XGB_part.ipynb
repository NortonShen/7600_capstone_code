{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dd364ec-3703-42c3-95d4-946ec8d041d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T16:38:54.394374Z",
     "start_time": "2024-08-23T16:38:53.853880Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-10 09:44:31.648951: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "import joblib\n",
    "import shap\n",
    "import category_encoders as ce\n",
    "import xgboost as xgb\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LambdaCallback\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dense, Dropout, Bidirectional, GRU\n",
    "from keras.layers import MaxPooling1D, Flatten, Conv1D\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "555c393a-8134-4905-b200-6e8cd9cc2b80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T16:38:56.984363Z",
     "start_time": "2024-08-23T16:38:56.935703Z"
    }
   },
   "outputs": [],
   "source": [
    "df_nasdaq = pd.read_csv('df_nasdaq.csv')\n",
    "df_sp500 = pd.read_csv('df_sp500.csv')\n",
    "df_dji = pd.read_csv('df_dji.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "963aad0e-fad5-4862-9603-fc2b5916fb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df_nasdaq: (1372, 19)\n",
      "Shape of df_sp500: (1372, 19)\n",
      "Shape of df_dji: (1372, 19)\n"
     ]
    }
   ],
   "source": [
    "stocks = {'df_nasdaq': df_nasdaq, 'df_sp500': df_sp500, 'df_dji': df_dji}\n",
    "\n",
    "for name, df in stocks.items():\n",
    "    print(f'Shape of {name}: {df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa053c09-ab8c-4d6d-b707-cd4417310f9f",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb87523f-fe2e-40e4-8b18-47b188397d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x280.8 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x280.8 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjgAAAERCAYAAAB2Pt2VAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAvnUlEQVR4nO3debxVVfnH8c8j5BQIGmiKCg44oJbayqFELc2ccMpUSoVSsWyyorLUHFKz1Moyf86iYqZmIo7lEA6l5VJJsSIHQCQ1VMABFIHn98daNzfHe7nnTuecu+/3/Xqd1z17rbXXfs653M1z1lp7H3N3RERERMpkuXoHICIiItLZlOCIiIhI6SjBERERkdJRgiMiIiKlowRHRERESkcJjoiIiJSOEpwGYmbjzOy0/Hy4mU0t1D1pZjvXKzYRka6icx+YmZvZhvWOo0yU4DQod7/f3TcubG/m7pOaa5tPDgvN7I3C4+COHL94wqkFM9vZzJ6v1fGWxcyG5JNN73rHItLTtPHct7aZ3WBmL5vZPDObYmajc12zf8fNndvMrE8+b97ezDGmm9mCXP9S3r9PM+3uMLNTmynf18xe1Pmk9pTglMdP3b1P4XFtPYPprn/M3TVukR7qKmAmMBj4AHAY8FI7+vkM8DbwKTP7YDP1I9y9D7A1EIATmmlzBXComVlF+WHA1e6+qB1xSQcowakjM9vKzB41s9fN7FpgxULdUiMa+VPErm3sfzkzO87MnjGzV8zsOjNbrVB/ff5kMc/M7jOzzXL5GODzwHfzp5abc/lSQ6gVw8o7m9nzZvY9M3sRuLy147cS+yQzO83M/tIUg5l9wMyuNrPXzOxhMxtSaO9m9nUzezZ/mjvLzJYrvA8nmNkMM/uvmV1pZv1yXdOnvCPM7DngHuC+3O3cfOztzWwDM7snv46Xcxz9K34/Y83s8fx+Xmtmxd/nvmY2Ocf+jJntnsv7mdmlZvaCmc3Kr7lX9b9lke6nE899HwXGufub7r7I3R9z9/eMwlRhFHAB8DhwaEuN3H0WcDuweTPVE0hJ1vBC7KsCewNXmtk2Zvagmc3Nf+/nmdnyzR0nn/+OLGyPNrMHCtubmNmdZvaqmU01s4MKdXua2T/yezvLzMZW+R6UjhKcOsn/sCeQPoGsBlxP+hTRmb4G7AfsBKwFzAF+Xai/HRgKrA48ClwN4O4X5edNo0IjqjzeB0mvZTAwporjt+YQ0qefQcAGwIPA5fkY/wROqmi/P+nT1dbAvsAXc/no/PgEsD7QBzivYt+dgE2BTwM75rL++fU/CBjw4/w6NgXWAU6u6OMgYHdgPeBD+ZiY2TbAlcB3gP65/+l5n3HAImBDYCtgN+B/JzaRsunkc99DwK/N7BAzW7ed8QwGdiad864GDl9G23WAPYHHKuvcfQFwXcX+BwH/cve/A4uBbwIDgO2BXYBj2hHv+4E7gd+Qzt2HAOeb2bDc5FLgaHfvS0rE7mnrMUrD3fWow4P0n9x/ACuU/QU4LT/fGXi+UDcd2LWFvsYBbwFz8+PlXP5PYJdCuzWBd4DezfTRH3CgX6HP0yraOLBhxXGL8S4EVizUt+X4la93EnB8Yfsc4PbC9ghgckVsuxe2jwHuzs/vBo4p1G3cFAcwJO+7fqG+qew9cRba7Ac8VvH7ObSw/VPggvz8QuDnzfSxBmlYfKVC2UjgT/X+96mHHl316ORz36rAmcCTpARiMvDRXNf0dzy34rGweG4jTTdNzs8H5X62qjj+G3nfGcD5xb/Zinh2yO1WzNt/Br7ZQttjgRsL2/87v+bz35GFutHAA/n5wcD9FX1dCJyUnz8HHA2sUu/fdb0fGsGpn7WAWZ7/RWYzOtDf2e7ePz8G5LLBwI15SHQuKeFYDKxhZr3M7Mw8XfIa744oDHhPz9Wb7e5vFbZbPH6V/RXn0hc0s1250G9m4fkM0ntM/jmjoq53RRzFfd/DzNYws9/mId/XgPG89716sfB8fiG+dYBnmul2MPA+4IXCe3Qh6VOZSFl12rnP3ee4+3Huvhnp73kyMMFsqXUwAwrnxv6kkY+iw3l39HoWcC9pyqpov7z/YHc/xtNoTXPxPAC8DOxnZhsA2zQdz8w2MrNbLC0LeA04g/adbwcD2zadM/J54/OkEXRIo2F7AjPM7F4z274dxygFJTj18wIwqOIPsV1DrMswE9ij+Mft7ivmP+LPkaZxdgX6kT7tQJqKgfRpotJ8YOXCduVivMp9lnX8rrBO4fm6pE+J5J+DK+oWsXTC5C08b3JGLt/C3VchzdNXLiZsyUzSFFtz5W+z9Al4lXyyFimrLjn3ufvLwNmkBKratX4fI03Tfz8nHi8C2wKfs/ZfcHAlKWk6FPiDuzedZ/4P+BcwNJ9DfkDL55A3aflcOxO4t+K82sfdvwzg7g+7+76kD0oTSNNmPZISnPp5kPSf7NfN7H1mdgAp2+9MFwCn5zlmzGygme2b6/qS/nN9hfSHdEbFvi+R1qsUTSb94ffKi2R36sDxu8J3zGzVPE/+DaDpSrJrgG+a2XqWLu88A7jWW76qYTawhKVff1/SMPU8MxtEWk9TrUuBL5jZLpYWPA8ys03c/QXgj8A5ZrZKrtvAzFp7X0W6s04795nZT8xsczPrbWZ9gS8DT7v7K1V2MYq0nmUYsGV+bA6sBOzRnphICc6uwFGkK6ua9AVeA94ws01yrC2ZDBxgZitburDjiELdLcBGZnZYfv/eZ2YfNbNNzWx5M/u8mfVz93fy8Za083V0e0pw6sTdFwIHkOZWXyXNq/6+kw9zLjAR+KOZvU5akLdtrruSNCw8C/hHriu6FBiWh0An5LJvkNa+zCUNiU5g2ZZ1/K5wE/AI6eRwK+k1AFxGWtB4HzCNtF7pay114u7zgdOBP+fXvx1wCmnx8rzcd9W/K3f/G/AF4Od5/3t5d0TpcGB50u9gDvA70lolkVLq5HPfysCNpHPSs6S/q32q2dHSVY4HAb9y9xcLj2mk80XlNFVV3H06aU3R+0nnvyZjSSPnrwMX8+4HsOb8nLRW6CVSknR1of/XSRcjHEIanX4R+AmwQm5yGDA9T4N9iXSu7pFs6WlQaRRm9kngEnevHEWRZpiZk4Z+n653LCLSfjr3SWfRCE7j2pw02iAi0pPo3CedQndtbUBmdi5pmLVdQ6QiIt2Rzn3SmTRFJSIiIqWjKSoREREpHSU4IiIiUjo9bg3OgAEDfMiQIfUOQ6RbeOSRR15294H1jqOnufnmm33EiGq/Ak6kx2v2hok9LsEZMmQIMcZ6hyHSLZhZR74+RESkbjRFJSIiIqWjBEdERERKRwmOiIiIlI4SHBERESkdJTgiIiJSOkpwREREpHSU4IiIiEjp9Lj74Dwxax5Djru13mGI1NX0M/eqdwgiIl1KIzgiIiJSOkpwREREpHSU4IiIiEjpKMERERGR0lGCIyIiIqWjBEdERERKRwmOiIiIlI4SHBERESkdJTgiIiJSOlXdydjM9gNuBDZ193+10GYSMNbdo5ndBnzO3edWtOkDnAPsCswFXge+5+5/NbM33L1PO1+HiEhp7DN1D5i6qN5hiNSVj+3Yly1UO4IzEngg/2yVu+9ZmdxklwCvAkPd/SPAF4ABVcYgIiIiUpVWE5w86rIDcARwSKF8JTP7rZn908xuBFYq1E03swEV/WwAbAuc4O5LANx9mrvfWtHOzOwsM5tiZk+Y2cG5fE0zu8/MJue64bl8NzN70MweNbPrc7wiIiLSg1UzgrMvcIe7/xt4xcw+ksu/DMx3902Bk4CPtNRBthkw2d0Xt9LuAGBL4MOkqayzzGxN4HPAH9y9qW5yTqJOAHZ1962BCHyrskMzG2Nm0czi4vnzWn3BIiIi0r1VM8E1Ejg3P/9t3n4E2BH4JYC7P25mj3dSTDsA1+RE6CUzuxf4KPAwcJmZvQ+Y4O6TzWwnYBjwZzMDWB54sLJDd78IuAhghTWHeifFKSIiIg1qmQmOma0GfBLYwswc6AW4mX2nHcd6EviwmfWqYhTnPdz9PjPbEdgLGGdmPwPmAHe6e1Vrg0RERKRnaG2K6kDgKncf7O5D3H0dYBowHLiPNG2EmW0OfGhZHbn7M6QppFMsD7eY2RAz26ui6f3AwWbWy8wGkkaK/mZmg4GX3P1i0mLlrYGHgI+b2Ya5v/eb2UbVvngR6f5CCCeEECYVtp8MIRzcwT6nhxAO7XBwIlI3rU1RjQR+UlF2Qy7/FnC5mf0T+Cdp2qqouamgI0mXiT9tZguAl4HK0aAbge2Bv+c+vuvuL5rZKOA7ZvYO8AZwuLvPNrPRwDVmtkLe/wTg3628LhFpYCGE44HTgNExxivasm+McbMq+j8I+DppPd87wAzgauCXMcaFbY9YRBrNMhMcd/9EM2W/LGweUllvZr2AvsBrzez7GnBUC8fqk386Ken5TkX9FcB7TnTufg9pjY6IlEAIYTnSeeJVYAzN/N13sP+TgG/mx4QY45wQwmbAccCapGRHRLq5jt1Fp3lPApe4+ztd0LeIlN+ngUHAfsAtIYTNY4xTmipDCHsBZwHrApOAp4s7hxCmAyfEGMdXdhxCGAKcCHwxxnhlU3mM8UngsJYCCiHsBPwU2AR4Afh5jPHCXLcq6SKGT5LOqc8DX4ox3p/r98vH3CDve1qM8eoq3wsRaadO/6oGd9/E3b/X2f2KSI8xBrg9xngr8DhwdFNFCGED4PfAGUB/0pWczY4Kt2A3wEhXhFYlhLAecAfwf8AHgNHAj0MIn81NvgOsDAzOMe1PSnIIIXwKuBQ4FlgNGAWcF0LYsQ0xi0g7dMUIjohIu4QQ1gL2BpqSh0uBU0II340xLiBNi/+tMDrzxxDCBNKITzUGAi+3cZ3NSODRGOO4vP1QCOFC0prC64GFpMRnY+CxGGNxDeA3gHObRnOAv4UQxgOHky7UEJEuoi/bFJFGcgRp7c0teXs86S7pTVdFrQ1Mr9hnWhv6nw0MCCEs34Z9mq4eLXoml0OaLrubtFZodgjhihDCGrluPeB7IYS5TQ/SCNBabTi+iLSDRnBEpCHkxcVHkKZ5ng8hNFX1Ik1TjQNmkdboFA1pw2H+SLo682Dgqir3mQnsWVG2fi4nxvgmcDxwfAjhg6Sk7CzSKM0MYFyM8aw2xCginUAJjog0it1JoyLbkBKZJh8G7gghbEFaO/PDEMJI0vTQzqTFyLGaA8QYp4cQfgScmxOqm2KMc0MImwDfA06OMVZeRXUNcGII4XDgN6R7cB1N+roaQggjSAud/026hcVbQNPNTH8BjAshPAT8hZSsbQFYjLGqmEWkfTRFJSKN4mjSZduPxBhfLDz+QPoKlqNjjE+TbkD6Q2Au6VLvS9pykBjjKaTkZAxppOhVUhIzhXSVU2X7aaQRnK8Cr5BGfk6MMV6Xm2wA3Ey6NcZ0YAEpWSLG+EfSIuizSPf9egH4OaAvBRbpYpZuO9NzhBBcH5xEqmNmj7h7aL1l4wghzAS+XUhAuh07e1HPOjGLNMPHVj3JZM0VagRHREojhDAIWIOKe+OISM+jBEdESiHfUG8KcEGM8dE6hyMidaZFxiJSCjHGCcCEOochIg1CIzgiIiJSOhrBERFpMBM3vp0RI0bUOwyRbk0jOCIiIlI6PW4E54lZ8xhy3K3t2nf6mXt1cjQiIiLSFTSCIyIiIqWjBEdERERKRwmOiIiIlI4SHBERESkdJTgiIiJSOkpwREREpHR63GXiIiKNbp+pe8DURVW1bcM3Lov0KBrBERERkdJRgiMiIiKl01AJjpm9Ue8YREREpPtrqARHREREpDM0fIJjZlua2UNm9riZ3Whmq5rZ6mb2SK7/sJm5ma2bt58xs5XrG7WIiIjUU8MnOMCVwPfc/UPAE8BJ7v5fYEUzWwUYDkRguJkNBv7r7vOLHZjZGDOLZhYXz59X6/hFRESkxho6wTGzfkB/d783F10B7Jif/wX4eN4+I/8cDtxf2Y+7X+Tuwd1Dr5X7dX3gItLthRAmhRBOqHccItI+DZ3gtOI+UkIzGLgJ+DCwA80kOCIiItKzNPQdotx9npnNMbPh7n4/cBjQNJpzP3A6cJ+7LzGzV4E9ge/XKVwR6QFCCIOBX5JGkBcANwDfjzEuCCF8C9g9xrhbbnslcBCwaq4/CDg5xjisTuGL9BiNNoKzspk9X3h8CxgFnGVmjwNbAqcCuPt0wEgjOQAPAHPdfU7twxaRniCE0Bu4FXiRNHq8HSnROTs3uQvYIYSwQt7eFZhJGm0G+FRuIyJdrKFGcNy9pYRruxbar1N4fgZpLY6ISFfZBhgKbBtjfBN4M6/TmRBC+CrpQojXgY+HEF4C3gIuIyU2fwR2AY6tR+AiPU2jjeCIiDSydYDZOblp8gywIjAwxujA3aSRm12BO0kjNp8KIWyQ959U04hFeiglOCIi1ZsJDAwhFO+1tT5ppGZ23r6LpROcR0iJzeeAh2OMr9UuXJGeq6GmqEREGkzvEMKKhe3HgaeBc0II3wb6Az8CLs+jN5ASnIuAN4FRMcYlIYR7gbHAuTWLXKSH0wiOiEjLTiJdKdX0eB04ElgbeA74G/BXUvICQIzxOeBZYGqM8dVcfBewClpgLFIzGsEREWlGjHHnZVSPaGXfjSq2zwfO74SwRKRKGsERERGR0lGCIyIiIqXT46aothjUj3jmXvUOQ0RERLqQRnBERESkdHrcCI6ISKObuPHtjBixzHXMItIKjeCIiIhI6SjBERERkdJRgiMiIiKlowRHRERESqfHLTJ+YtY8hhx361Jl03XZuIiISKloBEdERERKRwmOiIiIlI4SHBERESmdHrcGR0Sk0e0zdQ+YuqjZOh+r07ZINTSCIyIiIqWjBEdERERKRwmOiIiIlI4SHBERESmduiY4ZvZGxfZoMzsvP/+SmR3eyv7/ay8iIiLSpGGX47v7BfWOQUSkSQjhDeBTMcYHq2g7BJgGrBNjfL6rYxOR92rYKSozO9nMxubnHzWzx81sspmdZWZTCk3XMrM7zOwpM/tpncIVkW4shDAphHDCsspjjH2qSW5EpDHUewRnJTObXNheDZjYTLvLgaPc/UEzO7OibktgK+BtYKqZ/crdZ3ZFsCIiItI91DvBWeDuWzZtmNloIBQbmFl/oK+7N31y+g2wd6HJ3e4+L7f9BzAYmFnRxxhgDECvVQZ26gsQkZ4hhODA8BjjA3n7COAHwEDgJsCARTHG0YXdPhFC+D6wDvAgMCrG+EJNAxfpoRp2iqoN3i48X0wzSZu7X+Tuwd1Dr5X71S4yESmlEMKOwHnAUaSR59uAg5ppejCwIzAIeD9waq1iFOnp6j2C0yp3n2tmr5vZtu7+V+CQesckIqV0fAhhbEVZH+CuZtoeDlwfY7wnb18TQjimmXanxBhfBggh/AY4stOiFZFlavgEJzsCuNjMlgD3AvPqHI+IlM/pMcbTigUhhEkttB0ExIqyGc20K05HvQn0bXd0ItImdU1w3L1PxfY4YFx+fnKh6kl3/xCAmR1HPrEU2+ft4tocEZGuMou03q9oXeDZOsQiIs3oLiM4e5nZ90nxzgBG1zccEenhrgJuDyFcDtwHHAhshxIckYbRLRYZu/u17r6lu2/u7nu5++x6xyQiPVeM8V7gG8BlwBzSlZ0TWPqiBxGpI3P3esdQUyusOdTXHPWLpcqmn7lXfYIRaXBm9oi7h9ZbSgjhQeDmGOMZHe3Lzl7U4onZx3aXgXeRmrHmCvWXIiLSDiGEA4E7gIWkafNAurpKRBqAEhwRkfb5DHAJ0At4Gtg/xvhUfUMSkSZKcERE2iHGOLLeMYhIy7rFImMRERGRttAIjohIg5m48e2MGDGi3mGIdGs9LsHZYlA/oq6aEhERKTVNUYmIiEjpKMERERGR0lGCIyIiIqWjBEdERERKRwmOiIiIlE6PS3CemDWv3iGIiIhIF+txCY6IiIiUnxIcEZEGs8/UPbCzF9U7DJFuTQmOiIiIlI4SHBERESkdJTgiIiJSOkpwREREpHSU4IiIiEjpKMERERGR0uld7wBEROohhLA9cBKwPelc+C/glzHGK+oamIh0Co3giEiPE0LYDfgT8CCwPjAQ+AnwixDCKfWMTUQ6R5eM4JiZA1e7+6F5uzfwAvBXd9+70G4C8EF3366V/nYEfgF8CDjE3X9XqBsFnJA3T3N3ffoSkdb8GrgmxlhMZq4LIawMXBJCuBw4GXgfsATYF5gN/CjGOK5phxDCcODHwDBgDnA+8LMYo4cQdgbuAj4PnAEMAP4AHBFjfL1LX52IdNkIzpvA5ma2Ut7+FDCr2MDM+gMfAfqZ2fqt9PccMBr4TUUfq5GGmLcFtgFOMrNVOxq8iJRXCGEjYENgfDPVvwGMdM4COIiUlKwGHA38XwjhY7mfYcBtwFmkEaC9gK8ChxX66wXsBnwY2AjYCvh6574iEWlOV05R3Ub6gwcYCVxTUX8AcDPwW+CQZXXk7tPd/XHSJ6miTwN3uvur7j4HuBPYvaOBi0ipDcw/Z1VWxBgXAi8Dq+eih2KM42OMi2KMdwE3kD5sARwDXB9jvCnGuDjG+C/gPODwim6PizG+EWN8CZgAhE59NSLSrK5cZPxb4IdmdgtpaukyYHihfiRwKvAS6aRxRjuOMQiYWdh+PpctxczGAGMAeq0ysLJaRHqW2fnnINLC4v8JISxPmkqaDQwFplfsOx3YOj9fD/hkCOGAQv1yLH1OWhxjnF3YfhPo24HYRaRKXZbguPvjZjaElMjcVqwzszVIJ48H3N3N7B0z29zdp3RRLBcBFwGssOZQ74pjiEi38RTwLPA54O6KukMAJ40GfwwYUlE/hPRBCmAGcFmM8StdFaiItF9XXyY+ETgb2Bn4QKH8IGBVYJqZAaxCSoSOb2P/s3LfTdYGJrUrUhHpEfIC4K8CE0II00gLgxeQptR/AfwkxjgthACwXQhhJHAdsBPwGWDX3NX5wL0hhDuAO0iJ0UbAwBjjvTV8SSLSjK6+TPwy4BR3f6KifCSwu7sPcfchpMXGy1yH04I/ALuZ2ap5cfFuuUxEpEUxxtuBXYAdSdNOL5M+YI2NMRY/aF0H7Em6QupS4Csxxj/nPqYAewPHkq4S/S8wjnfX+IhIHZl758/YmNkb7t6nomxnYCzpKoM/A2t74eBm9ijwZXf/azP9fRS4kTTq8xbwortvluu+CPwgNz3d3S9fVmwrrDnU337hqXa+MpGexcwecfceuSg2hDAOWBRjPLLWx7azFzmAj9W9WEWqYM0VdslfT2Vyk8sm8e700XsWArv71pVlhbqHSdNPzdVdRhopEhEREQF0J2MREREpoYYa/zSz44HPVhRf7+6n1yMeEem5Yoyj6x2DiLRfQyU4OZFRMiMiIiIdoikqEZEGM3Hj27XAWKSDlOCIiIhI6SjBERERkdJRgiMiIiKl0+MSnC0G9at3CCIiItLFelyCIyIiIuWnBEdERERKRwmOiIiIlI4SHBERESkdJTgiIg1mn6l7YGcvqncYIt1aj0twnpg1r94hiIiISBfrcQmOiIiIlJ8SHBERESkdJTgiIiJSOkpwREREpHSU4IhIQwkhPBlCODg/HxJC8BDC2vWOS0S6l971DkBEyiOEMAnYHlgILAFeAf4M/CLG+Eg1fcQYN+vA8ccBnwfezsefBfwqxnh+lfsPAaYB68QYn29vHCJSfxrBEZHO9qMYY98YYz/gE8AM4KEQwv41Ov4VMcY+QH/gBOC8EMLONTo2ACGE99XyeCLyXhrBEZEuE2OcAZwQQlgT+FUIYQLwdeDLwCBgDnA1cEKMcTFACGF63h5f7CuEsCrwH+BjMcbHCuX3AXfGGH9UcewlwA0hhFeAAEzK7YcDPwaG5eOfD/wsxujA3/PuU0MIDvwkxvij/Hx4jPGB3MfOwF0xxt55exIwGRgCfBI4I4SwCdALeAv4LPAmcGqM8cJ2vJUi0kYawRGRWvgtKaHZGHge2ANYBdgX+CJwZGsdxBjnANcX24YQNiJNiV1W2T6E0Cuv5RkATM1lw4DbgLOAgcBewFeBw/JuH84/N44x9qlMmlrxReCXQL/8E+BA4GZgNeBrpNGkwW3oU0TaqeYjOGa2NvBr0qen5YBbgO+4+8JaxyIiNdO0nuUDMcYbCuWPhRCuAnYBqhnZuAi4OYTw7RjjW8ARwB0xxlmFNoeFEA4E3k8aQflhjPHmXHcMcH2M8aa8/a8QwnnA4cCV7Xpl7/pdjPGe/Hx+CAHgnhjjxFz2+xDCXGBL0rSdiHShmo7gmJkBvwcmuPtQYCOgD3B6LeMQkZprugrqlRDCyBDCwyGEV0II84CvkEZTWpWniP4DHBhC6A2MAi6uaHZVjLE/aSTlfGCX3BZgPWBkCGFu0wM4CVizA6+tyfRmyl6o2H4T6NsJxxKRVtR6BOeTwFvufjmAuy82s28C08xsGvBp0klpEDDe3U8BMLNDSfP2ywN/BY7J+74BnAvsDSwA9nX3l2r8mkSkdQeTrmh6ExgPHADcHmNcGEI4m7RGploXkkZu3gAWA7c21yjGOD+E8C3gSVISdS5p5OSyGONXWuh7SQvlb5BGhJqs1YZ9RaQOap3gbAYsdamou79mZs/lWLYBNgfmAw+b2a2kE+LBwMfd/R0zO590GeiVpBPOQ+5+vJn9FDgKOK3yoGY2BhgD0GuVqj4oikgnCCGsQ1ozM5r0d9yHNHI8G3gnhLAdaf3LP9vQ7VWkRcInAZc3LU5uTk6gTgV+FkK4jDSic28I4Q7gDsBJI8kDY4z35riWAEN5d1oN0nlrVAjhT6Tk5lttiFdE6qDRFhnf6e6vuPsC0lTWDqS5+Y+QEp7JeXv93H4haQ0PpBPQkOY6dfeL3D24e+i1cr8uDF9EgBNDCK+HEF4D7gM2JF35dEOM8Z+kxOQmYC5wHHBNWzrPi41/R1oQfGkVu/wGeBX4doxxCmnE91jS9NF/gXHkKbIY4wLgROCaPIV1fO7jq/l1vApcl/cRkQZm7l67g5ntCvzQ3XcslK1CurHWicC27j4ql59KuknYEmAtd/9+M/294e598vMDgb3dffSyYlhhzaH+9gtPddIrEik3M3vE3dsyfVQTIYSTSUnTbvWOpSvY2YscwMfqTh4iVbDmCms9gnM3sLKZHQ5gZr2Ac0ifhuYDnzKz1cxsJWA/0h1Q7wYONLPV8z6rmZkusxTpoUIIa5Cmo8+tdywi0rhqmuB4Gi7aH/ismT0F/Jt0E6wf5CZ/A24AHgducPfo7v8g3Y30j2b2OHAnnXPFg4h0MyGEnwHPAjfHGJtdXCwiAjWeoloWMxsNBHf/alceR1NUItVr1CmqstMUlUibNMQUlYiItGLixrcruRHpoIb5C3L3cejKBBEREekEGsERERGR0lGCIyIiIqWjBEdERERKRwmOiIiIlI4SHBERESkdJTgiIiJSOj0uwdlikL5sU0REpOx6XIIjItLo9pm6R71DEOn2lOCIiIhI6SjBERERkdJRgiMiIiKlowRHRERESqfHJThPzJpX7xBERESki/W4BEdERETKTwmOiIiIlE7vegcgItKZQgiTgJ2Ag2OM1xXKtwUeAmbEGIcUyj8PjAdOjjGeUuUxVgKuBLYENgB+GGM8raLNysB5wAG56AbgqzHGBe16YSLSJhrBEZEy+idwVEXZUbm80tHAq8ARIYReVfbvwF+AMcDfWmhzLrAJsDGwEbAp8LMq+xeRDlKCIyJl9HtgqxDC+gAhhL7AZ4DLi41CCJsCw4FRwJpAVbcQjjG+FWP8eYzxT8BblfV5hOdQ4MQY40sxxv8CJwKjQggrtv9liUi1lOCISBm9BVwNHJG3RwL3Ai9UtBsDPB5jvAW4jTSa0xk2BlYEHimUPQqsRBrNEZEupgRHRMrqYuALIYTepETm4mJlHkk5nHdHdS4F9gghrN0Jx+6bfxbvS9H0fJVO6F9EWqEER0RKKcY4BZhBmhpaHbijoslngT6kBcaQRnBmA0d2wuFfzz/7Fcqanr/WCf2LSCuU4IhImV1ESnAuizEurqgbA/QCpoQQXgSeB1albYuNWzKVNE22daFsK2AB8O8O9i0iVWiYy8TNbG3g18AwUuJ1C/Ad4GPATcC0XP5f4HOkxYC7u/vIQh8DSFdJrO3ub9f0BYhII7oGmMnSa2EIIQwDdgD2AR4uVK2e2+4J3LysjkMIKwBGOi/1zlNei2OM78QYF4QQxgOnhhCm5F1OBa6MMb5nUbKIdL6GSHDMzEhXPfyfu+9rZr1In7xOB24F7nf3vXPbHwNfAc4BzjGzld19fu7qQOBmJTciAulqJ+CuZqqOBh6NMVYmMS+GEK7P9ctMcEijNIPz8+HAScAVwOhcdizwK94dsbkB+GYbwheRDjB3r3cMmNkuwEnuvmOhbBXSqM1hwDHuvndOhH4FPO3uvzCzG4Dr3P3avM8k4HR3v7OlY62w5lB/+4WnuvDViJSHmT3i7qHecfQ0dvYi97EN8flTpDuw5gobZQ3OZlQMIbv7a8BzwIbAcDObnLd3BS7Lza4BDgEws7VIl1/eU9m5mY0xs2hmcfF8fdmmiIhI2XWXjwjFKarvAT8FvkSavjo/j/YcBNzg7pULCXH3i0hTXqyw5tD6D1mJSEMLIawL/KOF6vExxi/VMh4RabtGSXD+QVo/8z85aVkXeBrYrVA1kTSXjbsvMLM7gP1JIznfqkm0IlJqMcbnSJeQi0g31ShTVHcDK5vZ4QB5kfE5wDhgfkXbHYBnCtvXkBKbNYAHuzxSEZEuNnHj2+sdgki31xAJjqeVzvsDnzWzp0hXHbwF/CA3GW5mk83s76RFx98u7H4nsBZwrTfCimkRERGpu0aZosLdZwIjmqmaxNJ3A63cbxEwsIvCEhERkW6oIUZwRERERDqTEhwREREpHSU4IiIiUjpKcERERKR0lOCIiIhI6SjBERERkdJRgiMiIiKl0+MSnC0GtXhLHRERESmJHpfgiIiISPkpwREREZHSUYIjIiIipaMER0REREpHCY6IiIiUjhIcERERKR0lOCIiIlI6SnBERESkdJTgiIiISOmYu9c7hpoys9eBqfWOo0oDgJfrHUSVukus3SVOaIxYB7v7wDrH0OOssMIKUxYuXPhWveNoTe/evQcsWrSo3v9Gq9JdYlWc7fKyu+9eWdi7HpHU2VR3D/UOohpmFhVr5+oucUL3ilU61xZbbPFWjLHhf/chhNgd4oTuE6vi7DyaohIREZHSUYIjIiIipdMTE5yL6h1AGyjWztdd4oTuFat0ru7yu+8ucUL3iVVxdpIet8hYREREyq8njuCIiIhIyZX2Kioz2x04F+gFXOLuZ1bUrwBcCXwEeAU42N2n1zrOHEtrsX4LOBJYBMwGvujuMxotzkK7zwC/Az7q7rGGIRZjaDVWMzsIOBlw4O/u/rmaBvluHK39/tcFrgD65zbHuftttY5Tul4IYSPS7/oDpPPS4THGp2p4/LOBzwBDgC1ijFNai6u9dR2M8wPAVcAGwELgKeDoGOPsEMJ2wIXASsB04NAY43/zfu2q62CsE4D1gCXAG8DXYoyTG+09LcR7Eum8uEWMcUqjvZ9tUcoRHDPrBfwa2AMYBow0s2EVzY4A5rj7hsDPgZ/UNsqkylgfA4K7f4iUOPy0tlFWHSdm1hf4BvDX2ka4VAytxmpmQ4HvAx93982AY2sdZ46jmvf1BOA6d98KOAQ4v7ZRSg1dAPw6xrgR6d/FhTU+/gRgR6DyA9Sy4mpvXUc48NMY48Yxxi2AZ4AzQwjLAeOBr+Rj3gecCdDeuk4wKsb44RjjVsDZwGW5vNHeU0IIWwPbkX//Dfp+Vq2UCQ6wDfC0uz/r7guB3wL7VrTZl5QFQ0oadjEzq2GMTVqN1d3/5O7z8+ZDwNo1jhGqe08BfkRKFut5k7JqYj0K+LW7zwFw95p+siioJlYHVsnP+wH/qWF8UiMhhNWBrYFrctE1wNYhhJrdaDHG+ECMcWa1cbW3rhPifDXGOKlQ9BAwmDQi/1aM8YFcfgFwUH7e3rqOxjqvsNkPWNKI72kIYQVSwvTlQnHDvZ9tUdYEZxBQ/CN9Ppc128bdFwHzSEN+tVZNrEVHALd3aUTNazVOM9saWMfdb61lYM2o5j3dCNjIzP5sZg/laaJ6qCbWk4FDzex54Dbga7UJTWpsHWBWjHExQP75n1xeT8uKq711nSaPFnwZmAisS2H0Kcb4MrBcCGG1DtR1RoyXhBCeA04HRtGY7+mpwPgY4/RCWUO+n9Uqa4JTSmZ2KBCAs+odSyUzWw74GfDtesdSpd7AUGBnYCRwsZn1r2dAyzASGOfuawN7Alfl91tE4FektS3n1TuQlsQYj4wxrgv8gAY8f4cQtif931Kq6e+yniRnsXRGu3Yua7aNmfUmDR2+UpPoWogjay5WzGxX4HhgH3d/u0axFbUWZ19gc2CSmU0nzeNONLN63Mq7mvf0eWCiu7/j7tOAf5MSnlqrJtYjgOsA3P1BYEXS91RJucwEBoUQegHkn2ux9AhfPSwrrvbWdYq8KHoocHCMcQnwHGmqqql+ALAkxvhqB+o6TYzxKuAT5JHaBnpPdwI2BaaFEKaTzkN/ADakgd/P1pQ1wXkYGGpm65nZ8qSFmRMr2kwkDRUCHAjc4/W5KVCrsZrZVqSFZPvUca3IMuN093nuPsDdh7j7ENKc+D51uoqqmt//BNLoDWY2gDRl9WwNY2xSTazPAbsAmNmmpARndk2jlC6XrzCZTBqxI/98LMZY19/1suJqb11nxBVCOIO01mO/GGPTh75HgJVCCDvk7S8B13ewriMx9gkhrFPYHgG8CjTUexpjPDPGuFaMcUiMcQgpAfs0abSpYd7Ptirtjf7MbE/gF6TLai9z99PN7FQguvtEM1uRdJnhVqR/cIe4ez3+g6sm1ruALYAX8i7Pufs+jRZnRdtJwNg6Xibe2ntqwDnA7sBi4HR3/22DxjoMuBjoQ1pw/F13/2M9YpWuFULYhHTxw6rAHNIlwFNrePxfAgcAHyR9k/0rMcbNlhVXe+s6GOdmwBTSyOuCXDwtxrh/COFjpA+EK/Lu5ckv5f3aVdeBONcAbgLeTzrPvAqMjTE+2mjvaUXc04G982XiDfN+tlVpExwRERHpuco6RSUiIiI9mBIcERERKR0lOCIiIlI6SnBERESkdJTgiIiISOkowREREakhM3Mz26H1ltIRSnBERKThmNn6Zna9mb1oZm+Y2UwzuzHfEBMzG21mTzezX0vln8+JxUnN1E0ys7fzceaZ2WNm9pkW4rrJzK5soe5PZtawXxnR0yjBERGRRnQb6eamG5O+CmZ70tcHWDv7O5p0o70jzKxXM/U/cvc+pC9dvga41sw2aqbdhcCBld9dZ2ZDSV95cGE745NOpgRHREQaipl9gJTYXJC/Bsbd/Xl3v6A938WXv+JkOOnredYE9miprbsvIn3pZC/SHeQr3UH6qpTDKsrHAH919yfM7AwzezaPCD1jZscuI7b3jDiZ2Tgzu6Swva6Z/S6PZr1gZheZWd9lvmhRgiMiIo3F3V8BngQuMbPDzWxY/nqV9hoDPO7ut5BGho5uqWGeAvsK8A7w92ZiWwJcAhxVsc8o3h29+QewA2nk6Sjgx2b26fYEnr9W6J7c53rAMNKXYZ7bnv56EiU4IiLSiHYGJgHHkr5g8iUzO7Ei0VnPzOYWH6TRl//JCcLhwOW56FJgDzNbu+J4x+f9nwf2BT7j7u9Zy1PoY1Mz2zZv7w+8D7gWwN3Hu/t/8sjTPcCt5C/MbYe9SV+r9EN3X+Duc4ATgc+3MNUmmRIcERFpOO7+srv/wN23BvoD3wV+CHyh0Gyau/cvPoBjKrr6LOmLasfn7dtIU0xHVrQ7Pfexurt/zN1vXkZs/wFuIY0MkX+Od/cFAGb2dTN7wszm5KRpBDCwLa+/YD1g3Yok7m7SF+9+sJ199ghKcEREpKG5+3x3Hwc8DmzZxt3HkNbTTDGzF0kjNKvS8mLjal0EHGxmWwGfIE9PmdnHgZ+QpsEG5KTrZlpeHP066dvGi9YqPJ8B/LsykXP3Fd19VgfiLz0lOCIi0lDMbFUz+7GZbW5m7zOz3vmy7c2B+9vQzzDSWpj9SYlR02Mb0ujHnh0I8w/Ay8ANwIPuPiWXrwIsJo0SuZntxTIWNZOm31Y3s73NbDkz2x/YsVB/C7C8mf3AzPpaMii3k2VQgiMiIo1mIbA68HvSpd2zgROAr7v79W3o52jgUXe/2d1fLDweB65nGYuNW5MXG19MmkK6qFD1B+BK4G+kBOhA4MZl9PMM8I3cx6vA7qSkqal+PvBJ0uLifwHzSFNUW7Y39p7C3L3eMYiIiIh0Ko3giIiISOkowREREZHSUYIjIiIipaMER0REREpHCY6IiIiUjhIcERERKR0lOCIiIlI6SnBERESkdJTgiIiISOn8P5+Q+BjRa11JAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x280.8 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "target = 'Close'\n",
    "stock_name = {'nasdaq': df_nasdaq, 'sp500': df_sp500, 'dji': df_dji}\n",
    "\n",
    "n_top_features = 6\n",
    "\n",
    "for stock in stock_name.keys():\n",
    "    \n",
    "    df = stock_name[stock]\n",
    "    y = df[target]\n",
    "    X = df.drop(columns=[target, 'Date'])\n",
    "    \n",
    "    train_size = int(len(df) * 0.8)\n",
    "    X_train, X_test = X[:train_size], X[train_size:]\n",
    "    y_train, y_test = y[:train_size], y[train_size:]\n",
    "    \n",
    "    encoder = ce.LeaveOneOutEncoder(return_df=True)\n",
    "    X_train_loo = encoder.fit_transform(X_train, y_train)\n",
    "    X_test_loo = encoder.transform(X_test)\n",
    "    \n",
    "    model = xgb.XGBRegressor(n_estimators=500, max_depth=5, eta=0.05)\n",
    "    model.fit(X_train_loo, y_train)\n",
    "      \n",
    "    filename = f\"xgb/{stock}_xgb_model.sav\"\n",
    "    joblib.dump(model, filename)\n",
    "    \n",
    "    feature_importance = model.feature_importances_\n",
    "    sorted_idx = np.argsort(feature_importance)\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axs[0].barh(range(n_top_features), feature_importance[sorted_idx[-n_top_features:]])\n",
    "    axs[0].set_title(f'{stock} Feature Importance')\n",
    "    axs[0].set_yticks(range(n_top_features))\n",
    "    axs[0].set_yticklabels(np.array(X_test_loo.columns)[sorted_idx[-n_top_features:]])\n",
    "    \n",
    "    explainer = shap.Explainer(model)\n",
    "    shap_values = explainer(X_test_loo)\n",
    "    \n",
    "    shap.summary_plot(shap_values, X_test_loo, plot_type=\"bar\", feature_names=X_test_loo.columns,\n",
    "                      max_display=n_top_features, show=False)\n",
    "    \n",
    "    axs[1].set_title(f'{stock} SHAP Values')\n",
    "    axs[1].set_xlabel('SHAP Value')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88114107-0ee9-4b55-8c4b-d82f3adb11ea",
   "metadata": {},
   "source": [
    "### Loss of Nasdaq without XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c43be53e-156d-46e7-8734-31bb020cc37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(stock):\n",
    "    stock = stock.to_numpy()\n",
    "    test_set_size = int(np.round(0.2 * len(stock)))\n",
    "    val_set_size = int(np.round(0.2 * len(stock)))\n",
    "    train_set_size = len(stock) - test_set_size - val_set_size\n",
    "    \n",
    "    train = stock[:train_set_size, :]\n",
    "    val = stock[train_set_size: train_set_size+val_set_size, :]\n",
    "    test = stock[train_set_size+val_set_size:, :]\n",
    "\n",
    "    return (train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcb13ca7-51c7-43d3-9f42-a6b9821e307b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = split_data(df_nasdaq.drop(columns=['Date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76889f6e-7e54-4599-83b2-5dc8c49641dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of scaled training Set: (824, 18)\n",
      "Shape of scaled training Set: (274, 18)\n",
      "Shape of scaled testing Set: (274, 18)\n"
     ]
    }
   ],
   "source": [
    "# Standardize the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_train = scaler.fit_transform(train)\n",
    "scaled_val = scaler.transform(val)\n",
    "scaled_test = scaler.transform(test)\n",
    "\n",
    "print(f'Shape of scaled training Set: {scaled_train.shape}')\n",
    "print(f'Shape of scaled training Set: {scaled_val.shape}')\n",
    "print(f'Shape of scaled testing Set: {scaled_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64a07e5d-0e33-4146-b3bc-c6dc305169c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X_train:(794, 30, 18), shape of y_train:(794,)\n",
      "shape of X_train:(244, 30, 18), shape of y_train:(244,)\n",
      "shape of X_test:(244, 30, 18), shape of y_test:(244,)\n"
     ]
    }
   ],
   "source": [
    "def createXY(dataset,lookback):\n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    for i in range(lookback, len(dataset)):\n",
    "            dataX.append(dataset[i - lookback:i, 0:dataset.shape[1]])\n",
    "            dataY.append(dataset[i,0])\n",
    "    return np.array(dataX),np.array(dataY)\n",
    "\n",
    "lookback = 30\n",
    "\n",
    "X_train, y_train = createXY(scaled_train,lookback)\n",
    "X_val, y_val = createXY(scaled_val,lookback)\n",
    "X_test, y_test = createXY(scaled_test,lookback)\n",
    "\n",
    "print(f\"shape of X_train:{np.shape(X_train)}, shape of y_train:{np.shape(y_train)}\")\n",
    "print(f\"shape of X_train:{np.shape(X_val)}, shape of y_train:{np.shape(y_val)}\")\n",
    "print(f\"shape of X_test:{np.shape(X_test)}, shape of y_test:{np.shape(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae7d9f98-e298-45eb-bd4f-9ede9965e477",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-09 10:44:57.739682: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-09 10:44:57.746550: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-09 10:44:57.746840: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-09 10:44:57.747431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-09 10:44:57.755632: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-09 10:44:57.755984: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-09 10:44:57.756223: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-09 10:44:58.319722: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-09 10:44:58.320090: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-09 10:44:58.320332: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-09 10:44:58.320565: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22302 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:0c:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 30, 50)            13800     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 30, 50)            0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 50)                20200     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,051\n",
      "Trainable params: 34,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-09 10:45:02.152131: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/50 [..............................] - ETA: 3:13 - loss: 0.2978 - mse: 0.2978 - mae: 0.4937"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-09 10:45:02.860143: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 5s 19ms/step - loss: 0.0248 - mse: 0.0248 - mae: 0.1079 - val_loss: 0.0123 - val_mse: 0.0123 - val_mae: 0.0893\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0070 - mse: 0.0070 - mae: 0.0625 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0598\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.0057 - mse: 0.0057 - mae: 0.0565 - val_loss: 0.0062 - val_mse: 0.0062 - val_mae: 0.0611\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.0051 - mse: 0.0051 - mae: 0.0538 - val_loss: 0.0049 - val_mse: 0.0049 - val_mae: 0.0545\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0516 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0459\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0479 - val_loss: 0.0043 - val_mse: 0.0043 - val_mae: 0.0511\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0491 - val_loss: 0.0045 - val_mse: 0.0045 - val_mae: 0.0523\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0472 - val_loss: 0.0025 - val_mse: 0.0025 - val_mae: 0.0391\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0473 - val_loss: 0.0078 - val_mse: 0.0078 - val_mae: 0.0734\n",
      "Epoch 10/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0467 - val_loss: 0.0051 - val_mse: 0.0051 - val_mae: 0.0574\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0468 - val_loss: 0.0030 - val_mse: 0.0030 - val_mae: 0.0429\n",
      "Epoch 12/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0454 - val_loss: 0.0038 - val_mse: 0.0038 - val_mae: 0.0484\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0441 - val_loss: 0.0062 - val_mse: 0.0062 - val_mae: 0.0656\n",
      "Epoch 14/50\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0431 - val_loss: 0.0067 - val_mse: 0.0067 - val_mae: 0.0693\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0400 - val_loss: 0.0027 - val_mse: 0.0027 - val_mae: 0.0414\n",
      "Epoch 16/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0428 - val_loss: 0.0054 - val_mse: 0.0054 - val_mae: 0.0608\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0458 - val_loss: 0.0187 - val_mse: 0.0187 - val_mae: 0.1241\n",
      "Epoch 18/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0433 - val_loss: 0.0073 - val_mse: 0.0073 - val_mae: 0.0705\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0402 - val_loss: 0.0049 - val_mse: 0.0049 - val_mae: 0.0562\n",
      "Epoch 20/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0384 - val_loss: 0.0021 - val_mse: 0.0021 - val_mae: 0.0356\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0386 - val_loss: 0.0048 - val_mse: 0.0048 - val_mae: 0.0555\n",
      "Epoch 22/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0397 - val_loss: 0.0016 - val_mse: 0.0016 - val_mae: 0.0319\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0372 - val_loss: 0.0023 - val_mse: 0.0023 - val_mae: 0.0375\n",
      "Epoch 24/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0372 - val_loss: 0.0024 - val_mse: 0.0024 - val_mae: 0.0419\n",
      "Epoch 25/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0393 - val_loss: 0.0025 - val_mse: 0.0025 - val_mae: 0.0393\n",
      "Epoch 26/50\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0378 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0303\n",
      "Epoch 27/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0355 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0258\n",
      "Epoch 28/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0369 - val_loss: 0.0023 - val_mse: 0.0023 - val_mae: 0.0380\n",
      "Epoch 29/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0348 - val_loss: 0.0086 - val_mse: 0.0086 - val_mae: 0.0829\n",
      "Epoch 30/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0351 - val_loss: 0.0040 - val_mse: 0.0040 - val_mae: 0.0529\n",
      "Epoch 31/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0349 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0486\n",
      "Epoch 32/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0354 - val_loss: 0.0018 - val_mse: 0.0018 - val_mae: 0.0335\n",
      "Epoch 33/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0376 - val_loss: 0.0017 - val_mse: 0.0017 - val_mae: 0.0319\n",
      "Epoch 34/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0336 - val_loss: 0.0018 - val_mse: 0.0018 - val_mae: 0.0327\n",
      "Epoch 35/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0336 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0290\n",
      "Epoch 36/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0360 - val_loss: 0.0023 - val_mse: 0.0023 - val_mae: 0.0375\n",
      "Epoch 37/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0359 - val_loss: 0.0016 - val_mse: 0.0016 - val_mae: 0.0326\n",
      "Epoch 38/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0328 - val_loss: 0.0031 - val_mse: 0.0031 - val_mae: 0.0426\n",
      "Epoch 39/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0346 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0655\n",
      "Epoch 40/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0324 - val_loss: 0.0028 - val_mse: 0.0028 - val_mae: 0.0412\n",
      "Epoch 41/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0328 - val_loss: 0.0027 - val_mse: 0.0027 - val_mae: 0.0400\n",
      "Epoch 42/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0322 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0297\n",
      "Epoch 43/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0330 - val_loss: 0.0041 - val_mse: 0.0041 - val_mae: 0.0531\n",
      "Epoch 44/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0354 - val_loss: 0.0019 - val_mse: 0.0019 - val_mae: 0.0335\n",
      "Epoch 45/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0332 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0286\n",
      "Epoch 46/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0297 - val_loss: 0.0047 - val_mse: 0.0047 - val_mae: 0.0597\n",
      "Epoch 47/50\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0323 - val_loss: 0.0017 - val_mse: 0.0017 - val_mae: 0.0358\n",
      "Epoch 48/50\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0339 - val_loss: 0.0021 - val_mse: 0.0021 - val_mae: 0.0352\n",
      "Epoch 49/50\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0301 - val_loss: 0.0028 - val_mse: 0.0028 - val_mae: 0.0422\n",
      "Epoch 50/50\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0296 - val_loss: 0.0024 - val_mse: 0.0024 - val_mae: 0.0378\n",
      "Model saved at 'xgb/nasdaq_lstm_model_without_xgb.h5'\n",
      "8/8 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# LSTM Training\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='Adam', metrics=['mse', 'mae'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=16)\n",
    "\n",
    "model.save('xgb/nasdaq_lstm_model_without_xgb.h5')\n",
    "print(\"Model saved at 'xgb/nasdaq_lstm_model_without_xgb.h5'\")\n",
    "\n",
    "# Prediction\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_copies_array = np.repeat(y_pred, X_train.shape[2], axis=-1) # the length of feature and target\n",
    "y_pred_inversed = scaler.inverse_transform(y_pred_copies_array)[:, 0]\n",
    "\n",
    "y_test_copies_array = np.repeat(y_test.reshape(-1, 1), X_train.shape[2], axis=-1)\n",
    "y_test_inversed = scaler.inverse_transform(y_test_copies_array)[:,0]\n",
    "\n",
    "# Convert y_pred_inversed to a dataframe and save as a csv file\n",
    "results_df = pd.DataFrame({'test': y_test_inversed,'lstm': y_pred_inversed})\n",
    "results_df.to_csv('xgb/nasdaq_lstm_predictions_without_xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3a49223-760c-4862-99d0-dbc58cfc458d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 30, 100)          27600     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 30, 100)           0         \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 100)              60400     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 88,101\n",
      "Trainable params: 88,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "50/50 [==============================] - 6s 39ms/step - loss: 0.0277 - mse: 0.0277 - mae: 0.1127 - val_loss: 0.0092 - val_mse: 0.0092 - val_mae: 0.0790\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0539 - val_loss: 0.0030 - val_mse: 0.0030 - val_mae: 0.0410\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0460 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0432\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0485 - val_loss: 0.0030 - val_mse: 0.0030 - val_mae: 0.0409\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0415 - val_loss: 0.0028 - val_mse: 0.0028 - val_mae: 0.0399\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0410 - val_loss: 0.0068 - val_mse: 0.0068 - val_mae: 0.0687\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0430 - val_loss: 0.0020 - val_mse: 0.0020 - val_mae: 0.0344\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0412 - val_loss: 0.0017 - val_mse: 0.0017 - val_mae: 0.0312\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0384 - val_loss: 0.0032 - val_mse: 0.0032 - val_mae: 0.0449\n",
      "Epoch 10/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0371 - val_loss: 0.0016 - val_mse: 0.0016 - val_mae: 0.0295\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0376 - val_loss: 0.0040 - val_mse: 0.0040 - val_mae: 0.0505\n",
      "Epoch 12/50\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0371 - val_loss: 0.0021 - val_mse: 0.0021 - val_mae: 0.0358\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0374 - val_loss: 0.0017 - val_mse: 0.0017 - val_mae: 0.0340\n",
      "Epoch 14/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0364 - val_loss: 0.0024 - val_mse: 0.0024 - val_mae: 0.0384\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0378 - val_loss: 0.0042 - val_mse: 0.0042 - val_mae: 0.0579\n",
      "Epoch 16/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0423 - val_loss: 0.0068 - val_mse: 0.0068 - val_mae: 0.0694\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0366 - val_loss: 0.0015 - val_mse: 0.0015 - val_mae: 0.0296\n",
      "Epoch 18/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0354 - val_loss: 0.0017 - val_mse: 0.0017 - val_mae: 0.0309\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0336 - val_loss: 0.0043 - val_mse: 0.0043 - val_mae: 0.0534\n",
      "Epoch 20/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0352 - val_loss: 0.0030 - val_mse: 0.0030 - val_mae: 0.0429\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0334 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0280\n",
      "Epoch 22/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0321 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0286\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0303 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0289\n",
      "Epoch 24/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0309 - val_loss: 0.0024 - val_mse: 0.0024 - val_mae: 0.0377\n",
      "Epoch 25/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0326 - val_loss: 0.0017 - val_mse: 0.0017 - val_mae: 0.0311\n",
      "Epoch 26/50\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0326 - val_loss: 0.0022 - val_mse: 0.0022 - val_mae: 0.0356\n",
      "Epoch 27/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0311 - val_loss: 0.0020 - val_mse: 0.0020 - val_mae: 0.0349\n",
      "Epoch 28/50\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0304 - val_loss: 0.0015 - val_mse: 0.0015 - val_mae: 0.0285\n",
      "Epoch 29/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0325 - val_loss: 0.0019 - val_mse: 0.0019 - val_mae: 0.0331\n",
      "Epoch 30/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0307 - val_loss: 0.0016 - val_mse: 0.0016 - val_mae: 0.0333\n",
      "Epoch 31/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0302 - val_loss: 0.0029 - val_mse: 0.0029 - val_mae: 0.0419\n",
      "Epoch 32/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0308 - val_loss: 0.0026 - val_mse: 0.0026 - val_mae: 0.0396\n",
      "Epoch 33/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0298 - val_loss: 0.0018 - val_mse: 0.0018 - val_mae: 0.0314\n",
      "Epoch 34/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0327 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0484\n",
      "Epoch 35/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0303 - val_loss: 0.0039 - val_mse: 0.0039 - val_mae: 0.0481\n",
      "Epoch 36/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0304 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0439\n",
      "Epoch 37/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0288 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0259\n",
      "Epoch 38/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0273 - val_loss: 0.0026 - val_mse: 0.0026 - val_mae: 0.0401\n",
      "Epoch 39/50\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0287 - val_loss: 0.0015 - val_mse: 0.0015 - val_mae: 0.0323\n",
      "Epoch 40/50\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0271 - val_loss: 0.0023 - val_mse: 0.0023 - val_mae: 0.0360\n",
      "Epoch 41/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0281 - val_loss: 0.0017 - val_mse: 0.0017 - val_mae: 0.0304\n",
      "Epoch 42/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0272 - val_loss: 0.0019 - val_mse: 0.0019 - val_mae: 0.0324\n",
      "Epoch 43/50\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0288 - val_loss: 0.0026 - val_mse: 0.0026 - val_mae: 0.0379\n",
      "Epoch 44/50\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0270 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0269\n",
      "Epoch 45/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0284 - val_loss: 0.0024 - val_mse: 0.0024 - val_mae: 0.0363\n",
      "Epoch 46/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0270 - val_loss: 0.0027 - val_mse: 0.0027 - val_mae: 0.0397\n",
      "Epoch 47/50\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0282 - val_loss: 9.8191e-04 - val_mse: 9.8191e-04 - val_mae: 0.0254\n",
      "Epoch 48/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0256 - val_loss: 0.0018 - val_mse: 0.0018 - val_mae: 0.0318\n",
      "Epoch 49/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0277 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0283\n",
      "Epoch 50/50\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0264 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0260\n",
      "Model saved at 'xgb/nasdaq_bi-lstm_model_without_xgb.h5'\n",
      "8/8 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Bi-LSTM Training\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(50, return_sequences=True), input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Bidirectional(LSTM(50)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='Adam', metrics=['mse', 'mae'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=16)\n",
    "\n",
    "model.save('xgb/nasdaq_bi-lstm_model_without_xgb.h5')\n",
    "print(\"Model saved at 'xgb/nasdaq_bi-lstm_model_without_xgb.h5'\")\n",
    "\n",
    "# Prediction\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_copies_array = np.repeat(y_pred, X_train.shape[2], axis=-1) # the length of feature and target\n",
    "y_pred_inversed = scaler.inverse_transform(y_pred_copies_array)[:, 0]\n",
    "\n",
    "y_test_copies_array = np.repeat(y_test.reshape(-1, 1), X_train.shape[2], axis=-1)\n",
    "y_test_inversed = scaler.inverse_transform(y_test_copies_array)[:,0]\n",
    "\n",
    "# Convert y_pred_inversed to a dataframe and save as a csv file\n",
    "results_df = pd.DataFrame({'test': y_test_inversed,'lstm': y_pred_inversed})\n",
    "results_df.to_csv('xgb/nasdaq_bi-lstm_predictions_without_xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bce5e668-e3d1-407c-988c-c80816f22302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 28, 32)            1760      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 14, 32)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 12, 64)            6208      \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 6, 64)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 6, 50)             23000     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 6, 50)             0         \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 50)                20200     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51,219\n",
      "Trainable params: 51,219\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "50/50 [==============================] - 5s 23ms/step - loss: 0.0503 - mse: 0.0503 - mae: 0.1601 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0485\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.0099 - mse: 0.0099 - mae: 0.0761 - val_loss: 0.0124 - val_mse: 0.0124 - val_mae: 0.0961\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0081 - mse: 0.0081 - mae: 0.0665 - val_loss: 0.0041 - val_mse: 0.0041 - val_mae: 0.0497\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0068 - mse: 0.0068 - mae: 0.0606 - val_loss: 0.0043 - val_mse: 0.0043 - val_mae: 0.0528\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0582 - val_loss: 0.0062 - val_mse: 0.0062 - val_mae: 0.0649\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0053 - mse: 0.0053 - mae: 0.0539 - val_loss: 0.0237 - val_mse: 0.0237 - val_mae: 0.1362\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0591 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0864\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0054 - mse: 0.0054 - mae: 0.0533 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0854\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0051 - mse: 0.0051 - mae: 0.0528 - val_loss: 0.0063 - val_mse: 0.0063 - val_mae: 0.0621\n",
      "Epoch 10/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0053 - mse: 0.0053 - mae: 0.0528 - val_loss: 0.0038 - val_mse: 0.0038 - val_mae: 0.0471\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0502 - val_loss: 0.0075 - val_mse: 0.0075 - val_mae: 0.0718\n",
      "Epoch 12/50\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0457 - val_loss: 0.0089 - val_mse: 0.0089 - val_mae: 0.0764\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0465 - val_loss: 0.0060 - val_mse: 0.0060 - val_mae: 0.0608\n",
      "Epoch 14/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0465 - val_loss: 0.0136 - val_mse: 0.0136 - val_mae: 0.0982\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0452 - val_loss: 0.0055 - val_mse: 0.0055 - val_mae: 0.0575\n",
      "Epoch 16/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0461 - val_loss: 0.0041 - val_mse: 0.0041 - val_mae: 0.0487\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0433 - val_loss: 0.0126 - val_mse: 0.0126 - val_mae: 0.0925\n",
      "Epoch 18/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0444 - val_loss: 0.0050 - val_mse: 0.0050 - val_mae: 0.0544\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0426 - val_loss: 0.0073 - val_mse: 0.0073 - val_mae: 0.0671\n",
      "Epoch 20/50\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0404 - val_loss: 0.0083 - val_mse: 0.0083 - val_mae: 0.0718\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0432 - val_loss: 0.0093 - val_mse: 0.0093 - val_mae: 0.0756\n",
      "Epoch 22/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0436 - val_loss: 0.0154 - val_mse: 0.0154 - val_mae: 0.1028\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0439 - val_loss: 0.0080 - val_mse: 0.0080 - val_mae: 0.0693\n",
      "Epoch 24/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0429 - val_loss: 0.0094 - val_mse: 0.0094 - val_mae: 0.0765\n",
      "Epoch 25/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0407 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0623\n",
      "Epoch 26/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0388 - val_loss: 0.0154 - val_mse: 0.0154 - val_mae: 0.1017\n",
      "Epoch 27/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0436 - val_loss: 0.0156 - val_mse: 0.0156 - val_mae: 0.1014\n",
      "Epoch 28/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0426 - val_loss: 0.0088 - val_mse: 0.0088 - val_mae: 0.0726\n",
      "Epoch 29/50\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0394 - val_loss: 0.0072 - val_mse: 0.0072 - val_mae: 0.0653\n",
      "Epoch 30/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0464 - val_loss: 0.0092 - val_mse: 0.0092 - val_mae: 0.0766\n",
      "Epoch 31/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0398 - val_loss: 0.0102 - val_mse: 0.0102 - val_mae: 0.0810\n",
      "Epoch 32/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0409 - val_loss: 0.0090 - val_mse: 0.0090 - val_mae: 0.0748\n",
      "Epoch 33/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0374 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0588\n",
      "Epoch 34/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0404 - val_loss: 0.0080 - val_mse: 0.0080 - val_mae: 0.0707\n",
      "Epoch 35/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0378 - val_loss: 0.0065 - val_mse: 0.0065 - val_mae: 0.0630\n",
      "Epoch 36/50\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0360 - val_loss: 0.0084 - val_mse: 0.0084 - val_mae: 0.0725\n",
      "Epoch 37/50\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0376 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0627\n",
      "Epoch 38/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0373 - val_loss: 0.0055 - val_mse: 0.0055 - val_mae: 0.0588\n",
      "Epoch 39/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0370 - val_loss: 0.0083 - val_mse: 0.0083 - val_mae: 0.0710\n",
      "Epoch 40/50\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0384 - val_loss: 0.0061 - val_mse: 0.0061 - val_mae: 0.0627\n",
      "Epoch 41/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0364 - val_loss: 0.0103 - val_mse: 0.0103 - val_mae: 0.0817\n",
      "Epoch 42/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0361 - val_loss: 0.0075 - val_mse: 0.0075 - val_mae: 0.0678\n",
      "Epoch 43/50\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0384 - val_loss: 0.0076 - val_mse: 0.0076 - val_mae: 0.0684\n",
      "Epoch 44/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0352 - val_loss: 0.0070 - val_mse: 0.0070 - val_mae: 0.0659\n",
      "Epoch 45/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0349 - val_loss: 0.0061 - val_mse: 0.0061 - val_mae: 0.0612\n",
      "Epoch 46/50\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0338 - val_loss: 0.0085 - val_mse: 0.0085 - val_mae: 0.0730\n",
      "Epoch 47/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0348 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0600\n",
      "Epoch 48/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0356 - val_loss: 0.0085 - val_mse: 0.0085 - val_mae: 0.0726\n",
      "Epoch 49/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0339 - val_loss: 0.0070 - val_mse: 0.0070 - val_mae: 0.0649\n",
      "Epoch 50/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0355 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0853\n",
      "Model saved at 'xgb/nasdaq_cnn-lstm_model_without_xgb.h5'\n",
      "8/8 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# CNN-LSTM Training\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(2))\n",
    "# Don't need flatten\n",
    "\n",
    "model.add(LSTM(50, activation='relu', return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='Adam', metrics=['mse', 'mae'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=16)\n",
    "\n",
    "model.save('xgb/nasdaq_cnn-lstm_model_without_xgb.h5')\n",
    "print(\"Model saved at 'xgb/nasdaq_cnn-lstm_model_without_xgb.h5'\")\n",
    "\n",
    "# Prediction\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_copies_array = np.repeat(y_pred, X_train.shape[2], axis=-1) # the length of feature and target\n",
    "y_pred_inversed = scaler.inverse_transform(y_pred_copies_array)[:, 0]\n",
    "\n",
    "y_test_copies_array = np.repeat(y_test.reshape(-1, 1), X_train.shape[2], axis=-1)\n",
    "y_test_inversed = scaler.inverse_transform(y_test_copies_array)[:,0]\n",
    "\n",
    "# Convert y_pred_inversed to a dataframe and save as a csv file\n",
    "results_df = pd.DataFrame({'test': y_test_inversed,'lstm': y_pred_inversed})\n",
    "results_df.to_csv('xgb/nasdaq_cnn-lstm_predictions_without_xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f22fc76e-07fb-4ee8-8bab-ca3d45a61fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 30, 32)            4992      \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 30, 32)            0         \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 32)                6336      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,361\n",
      "Trainable params: 11,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "50/50 [==============================] - 4s 29ms/step - loss: 0.0216 - mse: 0.0216 - mae: 0.1121 - val_loss: 0.0242 - val_mse: 0.0242 - val_mae: 0.1316\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0052 - mse: 0.0052 - mae: 0.0587 - val_loss: 0.0198 - val_mse: 0.0198 - val_mae: 0.1137\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0472 - val_loss: 0.0193 - val_mse: 0.0193 - val_mae: 0.1107\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0459 - val_loss: 0.0191 - val_mse: 0.0191 - val_mae: 0.1090\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0418 - val_loss: 0.0164 - val_mse: 0.0164 - val_mae: 0.1036\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0399 - val_loss: 0.0176 - val_mse: 0.0176 - val_mae: 0.1035\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0377 - val_loss: 0.0170 - val_mse: 0.0170 - val_mae: 0.1014\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0346 - val_loss: 0.0171 - val_mse: 0.0171 - val_mae: 0.1005\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0330 - val_loss: 0.0153 - val_mse: 0.0153 - val_mae: 0.0957\n",
      "Epoch 10/50\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0329 - val_loss: 0.0149 - val_mse: 0.0149 - val_mae: 0.0950\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0333 - val_loss: 0.0150 - val_mse: 0.0150 - val_mae: 0.0934\n",
      "Epoch 12/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0347 - val_loss: 0.0150 - val_mse: 0.0150 - val_mae: 0.0951\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0312 - val_loss: 0.0154 - val_mse: 0.0154 - val_mae: 0.0950\n",
      "Epoch 14/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0303 - val_loss: 0.0145 - val_mse: 0.0145 - val_mae: 0.0927\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0302 - val_loss: 0.0145 - val_mse: 0.0145 - val_mae: 0.0914\n",
      "Epoch 16/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0286 - val_loss: 0.0146 - val_mse: 0.0146 - val_mae: 0.0920\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0297 - val_loss: 0.0137 - val_mse: 0.0137 - val_mae: 0.0880\n",
      "Epoch 18/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0288 - val_loss: 0.0139 - val_mse: 0.0139 - val_mae: 0.0891\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0281 - val_loss: 0.0140 - val_mse: 0.0140 - val_mae: 0.0887\n",
      "Epoch 20/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0277 - val_loss: 0.0147 - val_mse: 0.0147 - val_mae: 0.0905\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0276 - val_loss: 0.0127 - val_mse: 0.0127 - val_mae: 0.0838\n",
      "Epoch 22/50\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0273 - val_loss: 0.0127 - val_mse: 0.0127 - val_mae: 0.0837\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0275 - val_loss: 0.0155 - val_mse: 0.0155 - val_mae: 0.0959\n",
      "Epoch 24/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0287 - val_loss: 0.0129 - val_mse: 0.0129 - val_mae: 0.0830\n",
      "Epoch 25/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0267 - val_loss: 0.0135 - val_mse: 0.0135 - val_mae: 0.0857\n",
      "Epoch 26/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0282 - val_loss: 0.0120 - val_mse: 0.0120 - val_mae: 0.0799\n",
      "Epoch 27/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0292 - val_loss: 0.0122 - val_mse: 0.0122 - val_mae: 0.0815\n",
      "Epoch 28/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0257 - val_loss: 0.0118 - val_mse: 0.0118 - val_mae: 0.0793\n",
      "Epoch 29/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0253 - val_loss: 0.0114 - val_mse: 0.0114 - val_mae: 0.0801\n",
      "Epoch 30/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0263 - val_loss: 0.0123 - val_mse: 0.0123 - val_mae: 0.0798\n",
      "Epoch 31/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 9.6158e-04 - mse: 9.6158e-04 - mae: 0.0243 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0774\n",
      "Epoch 32/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0259 - val_loss: 0.0115 - val_mse: 0.0115 - val_mae: 0.0761\n",
      "Epoch 33/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0259 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0769\n",
      "Epoch 34/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 9.4918e-04 - mse: 9.4918e-04 - mae: 0.0243 - val_loss: 0.0110 - val_mse: 0.0110 - val_mae: 0.0786\n",
      "Epoch 35/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 9.9401e-04 - mse: 9.9401e-04 - mae: 0.0247 - val_loss: 0.0113 - val_mse: 0.0113 - val_mae: 0.0754\n",
      "Epoch 36/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0259 - val_loss: 0.0117 - val_mse: 0.0117 - val_mae: 0.0767\n",
      "Epoch 37/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0264 - val_loss: 0.0111 - val_mse: 0.0111 - val_mae: 0.0740\n",
      "Epoch 38/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 8.6985e-04 - mse: 8.6985e-04 - mae: 0.0229 - val_loss: 0.0124 - val_mse: 0.0124 - val_mae: 0.0801\n",
      "Epoch 39/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0259 - val_loss: 0.0115 - val_mse: 0.0115 - val_mae: 0.0751\n",
      "Epoch 40/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 9.8287e-04 - mse: 9.8287e-04 - mae: 0.0243 - val_loss: 0.0110 - val_mse: 0.0110 - val_mae: 0.0725\n",
      "Epoch 41/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 8.6281e-04 - mse: 8.6281e-04 - mae: 0.0231 - val_loss: 0.0110 - val_mse: 0.0110 - val_mae: 0.0714\n",
      "Epoch 42/50\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 9.1282e-04 - mse: 9.1282e-04 - mae: 0.0234 - val_loss: 0.0110 - val_mse: 0.0110 - val_mae: 0.0726\n",
      "Epoch 43/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 9.7743e-04 - mse: 9.7743e-04 - mae: 0.0244 - val_loss: 0.0110 - val_mse: 0.0110 - val_mae: 0.0743\n",
      "Epoch 44/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 9.3440e-04 - mse: 9.3440e-04 - mae: 0.0239 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0710\n",
      "Epoch 45/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 9.3693e-04 - mse: 9.3693e-04 - mae: 0.0239 - val_loss: 0.0101 - val_mse: 0.0101 - val_mae: 0.0707\n",
      "Epoch 46/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 8.7811e-04 - mse: 8.7811e-04 - mae: 0.0233 - val_loss: 0.0117 - val_mse: 0.0117 - val_mae: 0.0788\n",
      "Epoch 47/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 8.9644e-04 - mse: 8.9644e-04 - mae: 0.0235 - val_loss: 0.0104 - val_mse: 0.0104 - val_mae: 0.0705\n",
      "Epoch 48/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 8.3662e-04 - mse: 8.3662e-04 - mae: 0.0224 - val_loss: 0.0104 - val_mse: 0.0104 - val_mae: 0.0719\n",
      "Epoch 49/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 7.9017e-04 - mse: 7.9017e-04 - mae: 0.0220 - val_loss: 0.0101 - val_mse: 0.0101 - val_mae: 0.0675\n",
      "Epoch 50/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 8.3922e-04 - mse: 8.3922e-04 - mae: 0.0225 - val_loss: 0.0100 - val_mse: 0.0100 - val_mae: 0.0689\n",
      "Model saved at 'xgb/nasdaq_gru_model_without_xgb.h5'\n",
      "8/8 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# GRU Training\n",
    "model = Sequential()\n",
    "model.add(GRU(units=32, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GRU(units=32))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='Adam', metrics=['mse', 'mae'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=16)\n",
    "\n",
    "model.save('xgb/nasdaq_gru_model_without_xgb.h5')\n",
    "print(\"Model saved at 'xgb/nasdaq_gru_model_without_xgb.h5'\")\n",
    "\n",
    "# Prediction\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_copies_array = np.repeat(y_pred, X_train.shape[2], axis=-1) # the length of feature and target\n",
    "y_pred_inversed = scaler.inverse_transform(y_pred_copies_array)[:, 0]\n",
    "\n",
    "y_test_copies_array = np.repeat(y_test.reshape(-1, 1), X_train.shape[2], axis=-1)\n",
    "y_test_inversed = scaler.inverse_transform(y_test_copies_array)[:,0]\n",
    "\n",
    "# Convert y_pred_inversed to a dataframe and save as a csv file\n",
    "results_df = pd.DataFrame({'test': y_test_inversed,'lstm': y_pred_inversed})\n",
    "results_df.to_csv('xgb/nasdaq_gru_predictions_without_xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9854053-22a3-4390-ab7f-3584b6dac6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "\n",
    "class SRUCell(layers.Layer):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super(SRUCell, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.state_size = self.units  # Define the state size\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(shape=(input_shape[-1], self.units * 3),\n",
    "                                 initializer='glorot_uniform',\n",
    "                                 name='W')\n",
    "        self.U = self.add_weight(shape=(self.units, self.units * 2),\n",
    "                                 initializer='orthogonal',\n",
    "                                 name='U')\n",
    "        self.b = self.add_weight(shape=(self.units * 3,),\n",
    "                                 initializer='zeros',\n",
    "                                 name='b')\n",
    "        # New weight for transforming input to match hidden state dimension\n",
    "        self.V = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                 initializer='glorot_uniform',\n",
    "                                 name='V')\n",
    "        super(SRUCell, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, states):\n",
    "        h_prev = states[0]\n",
    "        x_W = tf.matmul(inputs, self.W) + self.b\n",
    "        z, f, r = tf.split(x_W, 3, axis=-1)\n",
    "        \n",
    "        h_U = tf.matmul(h_prev, self.U)\n",
    "        z_U, f_U = tf.split(h_U, 2, axis=-1)\n",
    "        \n",
    "        f = tf.sigmoid(f + f_U)\n",
    "        r = tf.sigmoid(r)\n",
    "        z = tf.tanh(z + z_U)\n",
    "        \n",
    "        # Transform inputs to match the hidden state dimension\n",
    "        inputs_transformed = tf.matmul(inputs, self.V) \n",
    "        h = f * h_prev + (1 - f) * z\n",
    "        h = r * h + (1 - r) * inputs_transformed\n",
    "        \n",
    "        return h, [h]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(SRUCell, self).get_config()\n",
    "        config.update({\n",
    "            'units': self.units,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "class SRU(layers.RNN):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        cell = SRUCell(units)\n",
    "        super(SRU, self).__init__(cell, **kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(SRU, self).get_config()\n",
    "        config.update({\n",
    "            'units': self.cell.units,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c44280b-d1ac-4f1e-942d-87c572a23d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sru (SRU)                   (None, 30, 32)            4448      \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 30, 32)            0         \n",
      "                                                                 \n",
      " sru_1 (SRU)                 (None, 32)                6240      \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,721\n",
      "Trainable params: 10,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "50/50 [==============================] - 7s 103ms/step - loss: 0.0490 - mse: 0.0490 - mae: 0.1576 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0266\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 5s 96ms/step - loss: 0.0189 - mse: 0.0189 - mae: 0.1030 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0525\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 5s 95ms/step - loss: 0.0116 - mse: 0.0116 - mae: 0.0835 - val_loss: 0.0080 - val_mse: 0.0080 - val_mae: 0.0817\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 5s 96ms/step - loss: 0.0095 - mse: 0.0095 - mae: 0.0730 - val_loss: 0.0086 - val_mse: 0.0086 - val_mae: 0.0841\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 5s 95ms/step - loss: 0.0083 - mse: 0.0083 - mae: 0.0699 - val_loss: 0.0028 - val_mse: 0.0028 - val_mae: 0.0450\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 5s 95ms/step - loss: 0.0074 - mse: 0.0074 - mae: 0.0649 - val_loss: 0.0062 - val_mse: 0.0062 - val_mae: 0.0686\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.0069 - mse: 0.0069 - mae: 0.0630 - val_loss: 0.0038 - val_mse: 0.0038 - val_mae: 0.0515\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 5s 96ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0607 - val_loss: 9.5224e-04 - val_mse: 9.5224e-04 - val_mae: 0.0243\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.0057 - mse: 0.0057 - mae: 0.0564 - val_loss: 0.0019 - val_mse: 0.0019 - val_mae: 0.0362\n",
      "Epoch 10/50\n",
      "50/50 [==============================] - 5s 96ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0576 - val_loss: 0.0021 - val_mse: 0.0021 - val_mae: 0.0379\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 5s 94ms/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0578 - val_loss: 0.0071 - val_mse: 0.0071 - val_mae: 0.0742\n",
      "Epoch 12/50\n",
      "50/50 [==============================] - 5s 95ms/step - loss: 0.0050 - mse: 0.0050 - mae: 0.0531 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0457\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 5s 93ms/step - loss: 0.0053 - mse: 0.0053 - mae: 0.0571 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0260\n",
      "Epoch 14/50\n",
      "50/50 [==============================] - 5s 93ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0515 - val_loss: 0.0021 - val_mse: 0.0021 - val_mae: 0.0366\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 5s 91ms/step - loss: 0.0051 - mse: 0.0051 - mae: 0.0536 - val_loss: 0.0020 - val_mse: 0.0020 - val_mae: 0.0355\n",
      "Epoch 16/50\n",
      "50/50 [==============================] - 4s 90ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0498 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0245\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 5s 97ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0492 - val_loss: 0.0042 - val_mse: 0.0042 - val_mae: 0.0547\n",
      "Epoch 18/50\n",
      "50/50 [==============================] - 5s 96ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0500 - val_loss: 0.0081 - val_mse: 0.0081 - val_mae: 0.0816\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 5s 96ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0495 - val_loss: 6.9599e-04 - val_mse: 6.9599e-04 - val_mae: 0.0206\n",
      "Epoch 20/50\n",
      "50/50 [==============================] - 5s 94ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0480 - val_loss: 0.0065 - val_mse: 0.0065 - val_mae: 0.0729\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - 5s 96ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0471 - val_loss: 8.7830e-04 - val_mse: 8.7830e-04 - val_mae: 0.0230\n",
      "Epoch 22/50\n",
      "50/50 [==============================] - 5s 101ms/step - loss: 0.0047 - mse: 0.0047 - mae: 0.0512 - val_loss: 0.0038 - val_mse: 0.0038 - val_mae: 0.0551\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - 5s 99ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0478 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0516\n",
      "Epoch 24/50\n",
      "50/50 [==============================] - 5s 97ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0422 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0286\n",
      "Epoch 25/50\n",
      "50/50 [==============================] - 5s 90ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0459 - val_loss: 7.8238e-04 - val_mse: 7.8238e-04 - val_mae: 0.0218\n",
      "Epoch 26/50\n",
      "50/50 [==============================] - 4s 89ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0442 - val_loss: 7.2800e-04 - val_mse: 7.2800e-04 - val_mae: 0.0213\n",
      "Epoch 27/50\n",
      "50/50 [==============================] - 5s 93ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0430 - val_loss: 0.0040 - val_mse: 0.0040 - val_mae: 0.0533\n",
      "Epoch 28/50\n",
      "50/50 [==============================] - 4s 88ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0446 - val_loss: 0.0019 - val_mse: 0.0019 - val_mae: 0.0340\n",
      "Epoch 29/50\n",
      "50/50 [==============================] - 4s 89ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0449 - val_loss: 0.0020 - val_mse: 0.0020 - val_mae: 0.0344\n",
      "Epoch 30/50\n",
      "50/50 [==============================] - 4s 88ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0420 - val_loss: 9.1197e-04 - val_mse: 9.1197e-04 - val_mae: 0.0252\n",
      "Epoch 31/50\n",
      "50/50 [==============================] - 5s 93ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0411 - val_loss: 0.0026 - val_mse: 0.0026 - val_mae: 0.0439\n",
      "Epoch 32/50\n",
      "50/50 [==============================] - 5s 96ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0422 - val_loss: 0.0024 - val_mse: 0.0024 - val_mae: 0.0408\n",
      "Epoch 33/50\n",
      "50/50 [==============================] - 4s 87ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0390 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0275\n",
      "Epoch 34/50\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0397 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0291\n",
      "Epoch 35/50\n",
      "50/50 [==============================] - 4s 88ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0398 - val_loss: 6.9783e-04 - val_mse: 6.9783e-04 - val_mae: 0.0214\n",
      "Epoch 36/50\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0397 - val_loss: 0.0017 - val_mse: 0.0017 - val_mae: 0.0326\n",
      "Epoch 37/50\n",
      "50/50 [==============================] - 5s 91ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0398 - val_loss: 0.0028 - val_mse: 0.0028 - val_mae: 0.0449\n",
      "Epoch 38/50\n",
      "50/50 [==============================] - 4s 89ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0385 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0293\n",
      "Epoch 39/50\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0380 - val_loss: 9.6080e-04 - val_mse: 9.6080e-04 - val_mae: 0.0237\n",
      "Epoch 40/50\n",
      "50/50 [==============================] - 5s 95ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0357 - val_loss: 0.0019 - val_mse: 0.0019 - val_mae: 0.0362\n",
      "Epoch 41/50\n",
      "50/50 [==============================] - 4s 88ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0368 - val_loss: 0.0029 - val_mse: 0.0029 - val_mae: 0.0473\n",
      "Epoch 42/50\n",
      "50/50 [==============================] - 4s 87ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0398 - val_loss: 0.0023 - val_mse: 0.0023 - val_mae: 0.0399\n",
      "Epoch 43/50\n",
      "50/50 [==============================] - 4s 89ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0331 - val_loss: 6.1407e-04 - val_mse: 6.1407e-04 - val_mae: 0.0188\n",
      "Epoch 44/50\n",
      "50/50 [==============================] - 4s 89ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0349 - val_loss: 6.6453e-04 - val_mse: 6.6453e-04 - val_mae: 0.0193\n",
      "Epoch 45/50\n",
      "50/50 [==============================] - 4s 88ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0381 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0259\n",
      "Epoch 46/50\n",
      "50/50 [==============================] - 4s 89ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0368 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0254\n",
      "Epoch 47/50\n",
      "50/50 [==============================] - 4s 88ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0369 - val_loss: 9.9482e-04 - val_mse: 9.9482e-04 - val_mae: 0.0269\n",
      "Epoch 48/50\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0370 - val_loss: 6.2453e-04 - val_mse: 6.2453e-04 - val_mae: 0.0187\n",
      "Epoch 49/50\n",
      "50/50 [==============================] - 4s 87ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0361 - val_loss: 0.0027 - val_mse: 0.0027 - val_mae: 0.0435\n",
      "Epoch 50/50\n",
      "50/50 [==============================] - 5s 91ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0323 - val_loss: 0.0060 - val_mse: 0.0060 - val_mae: 0.0699\n",
      "Model saved at 'xgb/nasdaq_sru_model_without_xgb.h5'\n",
      "8/8 [==============================] - 0s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "# SRU Training\n",
    "model = Sequential()\n",
    "\n",
    "model.add(SRU(units=32, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(SRU(units=32))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mse', 'mae'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=16)\n",
    "\n",
    "model.save('xgb/nasdaq_sru_model_without_xgb.h5')\n",
    "print(\"Model saved at 'xgb/nasdaq_sru_model_without_xgb.h5'\")\n",
    "\n",
    "# Prediction\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_copies_array = np.repeat(y_pred, X_train.shape[2], axis=-1) # the length of feature and target\n",
    "y_pred_inversed = scaler.inverse_transform(y_pred_copies_array)[:, 0]\n",
    "\n",
    "y_test_copies_array = np.repeat(y_test.reshape(-1, 1), X_train.shape[2], axis=-1)\n",
    "y_test_inversed = scaler.inverse_transform(y_test_copies_array)[:,0]\n",
    "\n",
    "# Convert y_pred_inversed to a dataframe and save as a csv file\n",
    "results_df = pd.DataFrame({'test': y_test_inversed,'lstm': y_pred_inversed})\n",
    "results_df.to_csv('xgb/nasdaq_sru_predictions_without_xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d283ecb6-eec4-4f04-96eb-aa1d42be806f",
   "metadata": {},
   "source": [
    "### Loss of Nasdaq with XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "360c253c-aae2-4311-809f-5f857540145a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = ['Open', 'High', 'Low', 'Volume', 'DailyReturn', 'Adj Close',\n",
    "           'MA_10', 'MA_20', 'MA_50', 'EMA_100', 'EMA_200', \n",
    "           'Volatility_bbh', 'Volatility_bbl', 'MACD', 'RSI', 'ATR','OBV']\n",
    "target = 'Close'\n",
    "\n",
    "# Result of XGBoost feature selection, according to 7600_code_XGB_part\n",
    "feature_xgb_nasdaq = ['Adj Close', 'High', 'Low', 'Open', 'MA_10', 'Volatility_bbl']\n",
    "feature_xgb_sp500 = ['Adj Close', 'High', 'Low', 'Open', 'MA_10', 'MA_20']\n",
    "feature_xgb_dji = ['Adj Close', 'High', 'Low', 'Open', 'MA_10', 'OBV']\n",
    "\n",
    "df_nasdaq_preprocessed = df_nasdaq[[target] + feature_xgb_nasdaq]\n",
    "df_sp500_preprocessed = df_sp500[[target] + feature_xgb_sp500]\n",
    "df_dji_preprocessed = df_dji[[target] + feature_xgb_dji]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b116ce0-cedb-4287-80fe-292a57a95386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of scaled training Set: (824, 7)\n",
      "Shape of scaled training Set: (274, 7)\n",
      "Shape of scaled testing Set: (274, 7)\n"
     ]
    }
   ],
   "source": [
    "train, val, test = split_data(df_nasdaq_preprocessed)\n",
    "\n",
    "# Standardize\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_train = scaler.fit_transform(train)\n",
    "scaled_val = scaler.transform(val)\n",
    "scaled_test = scaler.transform(test)\n",
    "\n",
    "print(f'Shape of scaled training Set: {scaled_train.shape}')\n",
    "print(f'Shape of scaled training Set: {scaled_val.shape}')\n",
    "print(f'Shape of scaled testing Set: {scaled_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f868747e-f950-435c-a5a2-91df5df1d410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X_train:(794, 30, 7), shape of y_train:(794,)\n",
      "shape of X_train:(244, 30, 7), shape of y_train:(244,)\n",
      "shape of X_test:(244, 30, 7), shape of y_test:(244,)\n"
     ]
    }
   ],
   "source": [
    "lookback = 30\n",
    "\n",
    "X_train, y_train = createXY(scaled_train,lookback)\n",
    "X_val, y_val = createXY(scaled_val,lookback)\n",
    "X_test, y_test = createXY(scaled_test,lookback)\n",
    "\n",
    "print(f\"shape of X_train:{np.shape(X_train)}, shape of y_train:{np.shape(y_train)}\")\n",
    "print(f\"shape of X_train:{np.shape(X_val)}, shape of y_train:{np.shape(y_val)}\")\n",
    "print(f\"shape of X_test:{np.shape(X_test)}, shape of y_test:{np.shape(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81be4c1e-4e89-4010-90a2-d038e093d22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_6 (LSTM)               (None, 30, 50)            11600     \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 30, 50)            0         \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 50)                20200     \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,851\n",
      "Trainable params: 31,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "50/50 [==============================] - 4s 18ms/step - loss: 0.0184 - mse: 0.0184 - mae: 0.0920 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0463\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0564 - val_loss: 0.0100 - val_mse: 0.0100 - val_mae: 0.0859\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0050 - mse: 0.0050 - mae: 0.0520 - val_loss: 0.0114 - val_mse: 0.0114 - val_mae: 0.0941\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0050 - mse: 0.0050 - mae: 0.0532 - val_loss: 0.0080 - val_mse: 0.0080 - val_mae: 0.0765\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0501 - val_loss: 0.0104 - val_mse: 0.0104 - val_mae: 0.0895\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0489 - val_loss: 0.0096 - val_mse: 0.0096 - val_mae: 0.0868\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0490 - val_loss: 0.0019 - val_mse: 0.0019 - val_mae: 0.0339\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0486 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0487\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0448 - val_loss: 0.0051 - val_mse: 0.0051 - val_mae: 0.0611\n",
      "Epoch 10/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0446 - val_loss: 0.0039 - val_mse: 0.0039 - val_mae: 0.0523\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0494 - val_loss: 0.0021 - val_mse: 0.0021 - val_mae: 0.0374\n",
      "Epoch 12/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0411 - val_loss: 0.0018 - val_mse: 0.0018 - val_mae: 0.0343\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0451 - val_loss: 0.0052 - val_mse: 0.0052 - val_mae: 0.0628\n",
      "Epoch 14/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0422 - val_loss: 0.0048 - val_mse: 0.0048 - val_mae: 0.0598\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0475 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0275\n",
      "Epoch 16/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0406 - val_loss: 0.0016 - val_mse: 0.0016 - val_mae: 0.0321\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0410 - val_loss: 0.0024 - val_mse: 0.0024 - val_mae: 0.0415\n",
      "Epoch 18/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0380 - val_loss: 0.0032 - val_mse: 0.0032 - val_mae: 0.0480\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0413 - val_loss: 0.0026 - val_mse: 0.0026 - val_mae: 0.0432\n",
      "Epoch 20/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0428 - val_loss: 0.0040 - val_mse: 0.0040 - val_mae: 0.0539\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0381 - val_loss: 0.0018 - val_mse: 0.0018 - val_mae: 0.0354\n",
      "Epoch 22/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0421 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0268\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0395 - val_loss: 0.0025 - val_mse: 0.0025 - val_mae: 0.0411\n",
      "Epoch 24/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0371 - val_loss: 0.0052 - val_mse: 0.0052 - val_mae: 0.0624\n",
      "Epoch 25/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0408 - val_loss: 0.0051 - val_mse: 0.0051 - val_mae: 0.0629\n",
      "Epoch 26/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0382 - val_loss: 0.0019 - val_mse: 0.0019 - val_mae: 0.0353\n",
      "Epoch 27/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0376 - val_loss: 0.0019 - val_mse: 0.0019 - val_mae: 0.0357\n",
      "Epoch 28/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0367 - val_loss: 0.0127 - val_mse: 0.0127 - val_mae: 0.1053\n",
      "Epoch 29/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0389 - val_loss: 0.0044 - val_mse: 0.0044 - val_mae: 0.0571\n",
      "Epoch 30/50\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0367 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0259\n",
      "Epoch 31/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0356 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0253\n",
      "Epoch 32/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0362 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0515\n",
      "Epoch 33/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0331 - val_loss: 0.0042 - val_mse: 0.0042 - val_mae: 0.0567\n",
      "Epoch 34/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0338 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0301\n",
      "Epoch 35/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0352 - val_loss: 0.0028 - val_mse: 0.0028 - val_mae: 0.0449\n",
      "Epoch 36/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0354 - val_loss: 9.8050e-04 - val_mse: 9.8050e-04 - val_mae: 0.0246\n",
      "Epoch 37/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0350 - val_loss: 0.0046 - val_mse: 0.0046 - val_mae: 0.0593\n",
      "Epoch 38/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0348 - val_loss: 0.0051 - val_mse: 0.0051 - val_mae: 0.0635\n",
      "Epoch 39/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0345 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0259\n",
      "Epoch 40/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0354 - val_loss: 0.0015 - val_mse: 0.0015 - val_mae: 0.0313\n",
      "Epoch 41/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0345 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0250\n",
      "Epoch 42/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0346 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0282\n",
      "Epoch 43/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0333 - val_loss: 8.8962e-04 - val_mse: 8.8962e-04 - val_mae: 0.0234\n",
      "Epoch 44/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0359 - val_loss: 0.0059 - val_mse: 0.0059 - val_mae: 0.0674\n",
      "Epoch 45/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0326 - val_loss: 0.0022 - val_mse: 0.0022 - val_mae: 0.0393\n",
      "Epoch 46/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0313 - val_loss: 0.0020 - val_mse: 0.0020 - val_mae: 0.0377\n",
      "Epoch 47/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0334 - val_loss: 0.0042 - val_mse: 0.0042 - val_mae: 0.0573\n",
      "Epoch 48/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0331 - val_loss: 9.4328e-04 - val_mse: 9.4328e-04 - val_mae: 0.0241\n",
      "Epoch 49/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0333 - val_loss: 0.0015 - val_mse: 0.0015 - val_mae: 0.0307\n",
      "Epoch 50/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0308 - val_loss: 8.4295e-04 - val_mse: 8.4295e-04 - val_mae: 0.0226\n",
      "Model saved at 'xgb/nasdaq_lstm_model_with_xgb.h5'\n",
      "8/8 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# LSTM Training\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='Adam', metrics=['mse', 'mae'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=16)\n",
    "\n",
    "model.save('xgb/nasdaq_lstm_model_with_xgb.h5')\n",
    "print(\"Model saved at 'xgb/nasdaq_lstm_model_with_xgb.h5'\")\n",
    "\n",
    "# Prediction\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_copies_array = np.repeat(y_pred, X_train.shape[2], axis=-1) # the length of feature and target\n",
    "y_pred_inversed = scaler.inverse_transform(y_pred_copies_array)[:, 0]\n",
    "\n",
    "y_test_copies_array = np.repeat(y_test.reshape(-1, 1), X_train.shape[2], axis=-1)\n",
    "y_test_inversed = scaler.inverse_transform(y_test_copies_array)[:,0]\n",
    "\n",
    "# Convert y_pred_inversed to a dataframe and save as a csv file\n",
    "results_df = pd.DataFrame({'test': y_test_inversed,'lstm': y_pred_inversed})\n",
    "results_df.to_csv('xgb/nasdaq_lstm_predictions_with_xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "79ac3db9-43d1-4b07-a1b1-ba33fb3b3213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_10 (Bidirecti  (None, 30, 100)          23200     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 30, 100)           0         \n",
      "                                                                 \n",
      " bidirectional_11 (Bidirecti  (None, 100)              60400     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 83,701\n",
      "Trainable params: 83,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "50/50 [==============================] - 7s 33ms/step - loss: 0.0263 - mse: 0.0263 - mae: 0.1084 - val_loss: 0.0115 - val_mse: 0.0115 - val_mae: 0.0907\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.0054 - mse: 0.0054 - mae: 0.0553 - val_loss: 0.0040 - val_mse: 0.0040 - val_mae: 0.0520\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0510 - val_loss: 0.0039 - val_mse: 0.0039 - val_mae: 0.0530\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0483 - val_loss: 0.0079 - val_mse: 0.0079 - val_mae: 0.0764\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0474 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0493\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0489 - val_loss: 0.0039 - val_mse: 0.0039 - val_mae: 0.0534\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0431 - val_loss: 0.0045 - val_mse: 0.0045 - val_mae: 0.0586\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0423 - val_loss: 0.0016 - val_mse: 0.0016 - val_mae: 0.0329\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0396 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0666\n",
      "Epoch 10/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0402 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0309\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0394 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0526\n",
      "Epoch 12/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0401 - val_loss: 0.0024 - val_mse: 0.0024 - val_mae: 0.0422\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0379 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0300\n",
      "Epoch 14/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0391 - val_loss: 0.0028 - val_mse: 0.0028 - val_mae: 0.0450\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0380 - val_loss: 0.0041 - val_mse: 0.0041 - val_mae: 0.0549\n",
      "Epoch 16/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0359 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0272\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0351 - val_loss: 0.0047 - val_mse: 0.0047 - val_mae: 0.0599\n",
      "Epoch 18/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0364 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0275\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0332 - val_loss: 0.0028 - val_mse: 0.0028 - val_mae: 0.0452\n",
      "Epoch 20/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0340 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0269\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0362 - val_loss: 0.0032 - val_mse: 0.0032 - val_mae: 0.0477\n",
      "Epoch 22/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0328 - val_loss: 0.0020 - val_mse: 0.0020 - val_mae: 0.0376\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0377 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0296\n",
      "Epoch 24/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0333 - val_loss: 0.0017 - val_mse: 0.0017 - val_mae: 0.0344\n",
      "Epoch 25/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0352 - val_loss: 0.0048 - val_mse: 0.0048 - val_mae: 0.0622\n",
      "Epoch 26/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0324 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0279\n",
      "Epoch 27/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0330 - val_loss: 0.0018 - val_mse: 0.0018 - val_mae: 0.0363\n",
      "Epoch 28/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0331 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0497\n",
      "Epoch 29/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0373 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0262\n",
      "Epoch 30/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0340 - val_loss: 0.0042 - val_mse: 0.0042 - val_mae: 0.0571\n",
      "Epoch 31/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0343 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0269\n",
      "Epoch 32/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0362 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0271\n",
      "Epoch 33/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0340 - val_loss: 0.0026 - val_mse: 0.0026 - val_mae: 0.0437\n",
      "Epoch 34/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0346 - val_loss: 0.0025 - val_mse: 0.0025 - val_mae: 0.0430\n",
      "Epoch 35/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0338 - val_loss: 0.0023 - val_mse: 0.0023 - val_mae: 0.0406\n",
      "Epoch 36/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0343 - val_loss: 9.4364e-04 - val_mse: 9.4364e-04 - val_mae: 0.0250\n",
      "Epoch 37/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0317 - val_loss: 8.2691e-04 - val_mse: 8.2691e-04 - val_mae: 0.0225\n",
      "Epoch 38/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0348 - val_loss: 9.4613e-04 - val_mse: 9.4613e-04 - val_mae: 0.0242\n",
      "Epoch 39/50\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0306 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0494\n",
      "Epoch 40/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0325 - val_loss: 0.0022 - val_mse: 0.0022 - val_mae: 0.0393\n",
      "Epoch 41/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0313 - val_loss: 8.3965e-04 - val_mse: 8.3965e-04 - val_mae: 0.0232\n",
      "Epoch 42/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0360 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0250\n",
      "Epoch 43/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0311 - val_loss: 0.0017 - val_mse: 0.0017 - val_mae: 0.0339\n",
      "Epoch 44/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0318 - val_loss: 7.9289e-04 - val_mse: 7.9289e-04 - val_mae: 0.0229\n",
      "Epoch 45/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0343 - val_loss: 7.5848e-04 - val_mse: 7.5848e-04 - val_mae: 0.0214\n",
      "Epoch 46/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.0020 - mse: 0.0020 - mae: 0.0325 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0255\n",
      "Epoch 47/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0314 - val_loss: 8.5267e-04 - val_mse: 8.5267e-04 - val_mae: 0.0233\n",
      "Epoch 48/50\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0300 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0271\n",
      "Epoch 49/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0287 - val_loss: 0.0030 - val_mse: 0.0030 - val_mae: 0.0474\n",
      "Epoch 50/50\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0285 - val_loss: 0.0022 - val_mse: 0.0022 - val_mae: 0.0402\n",
      "Model saved at 'xgb/nasdaq_bi-lstm_model_with_xgb.h5'\n",
      "8/8 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Bi-LSTM Training\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(50, return_sequences=True), input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Bidirectional(LSTM(50)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='Adam', metrics=['mse', 'mae'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=16)\n",
    "\n",
    "model.save('xgb/nasdaq_bi-lstm_model_with_xgb.h5')\n",
    "print(\"Model saved at 'xgb/nasdaq_bi-lstm_model_with_xgb.h5'\")\n",
    "\n",
    "# Prediction\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_copies_array = np.repeat(y_pred, X_train.shape[2], axis=-1) # the length of feature and target\n",
    "y_pred_inversed = scaler.inverse_transform(y_pred_copies_array)[:, 0]\n",
    "\n",
    "y_test_copies_array = np.repeat(y_test.reshape(-1, 1), X_train.shape[2], axis=-1)\n",
    "y_test_inversed = scaler.inverse_transform(y_test_copies_array)[:,0]\n",
    "\n",
    "# Convert y_pred_inversed to a dataframe and save as a csv file\n",
    "results_df = pd.DataFrame({'test': y_test_inversed,'lstm': y_pred_inversed})\n",
    "results_df.to_csv('xgb/nasdaq_bi-lstm_predictions_with_xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a60fe102-b2ff-44c0-bac8-ef263b7ffc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-10 09:48:55.858760: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-10 09:48:55.864835: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-10 09:48:55.865137: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-10 09:48:55.865986: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-10 09:48:55.873687: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-10 09:48:55.874000: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-10 09:48:55.874231: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-10 09:48:56.626079: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-10 09:48:56.626502: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-10 09:48:56.626778: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-10 09:48:56.627029: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22302 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:0e:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 28, 32)            704       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 14, 32)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 12, 64)            6208      \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 6, 64)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 6, 50)             23000     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 6, 50)             0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 50)                20200     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,163\n",
      "Trainable params: 50,163\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-10 09:49:00.450404: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101\n",
      "2024-11-10 09:49:01.983793: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 6s 27ms/step - loss: 0.0508 - mse: 0.0508 - mae: 0.1585 - val_loss: 0.0128 - val_mse: 0.0128 - val_mae: 0.0970\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0111 - mse: 0.0111 - mae: 0.0780 - val_loss: 0.0076 - val_mse: 0.0076 - val_mae: 0.0751\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0087 - mse: 0.0087 - mae: 0.0685 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0895\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0088 - mse: 0.0088 - mae: 0.0676 - val_loss: 0.0121 - val_mse: 0.0121 - val_mae: 0.0955\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0067 - mse: 0.0067 - mae: 0.0615 - val_loss: 0.0060 - val_mse: 0.0060 - val_mae: 0.0654\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0596 - val_loss: 0.0092 - val_mse: 0.0092 - val_mae: 0.0828\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0054 - mse: 0.0054 - mae: 0.0536 - val_loss: 0.0055 - val_mse: 0.0055 - val_mae: 0.0570\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.0084 - mse: 0.0084 - mae: 0.0666 - val_loss: 0.0075 - val_mse: 0.0075 - val_mae: 0.0724\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0054 - mse: 0.0054 - mae: 0.0549 - val_loss: 0.0096 - val_mse: 0.0096 - val_mae: 0.0829\n",
      "Epoch 10/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0509 - val_loss: 0.0042 - val_mse: 0.0042 - val_mae: 0.0536\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0566 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0469\n",
      "Epoch 12/50\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.0056 - mse: 0.0056 - mae: 0.0556 - val_loss: 0.0070 - val_mse: 0.0070 - val_mae: 0.0695\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0489 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0455\n",
      "Epoch 14/50\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.0054 - mse: 0.0054 - mae: 0.0538 - val_loss: 0.0082 - val_mse: 0.0082 - val_mae: 0.0755\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0474 - val_loss: 0.0045 - val_mse: 0.0045 - val_mae: 0.0547\n",
      "Epoch 16/50\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0485 - val_loss: 0.0062 - val_mse: 0.0062 - val_mae: 0.0638\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0475 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0447\n",
      "Epoch 18/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0492 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0595\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0504 - val_loss: 0.0085 - val_mse: 0.0085 - val_mae: 0.0773\n",
      "Epoch 20/50\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0432 - val_loss: 0.0065 - val_mse: 0.0065 - val_mae: 0.0654\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0452 - val_loss: 0.0127 - val_mse: 0.0127 - val_mae: 0.0964\n",
      "Epoch 22/50\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0430 - val_loss: 0.0047 - val_mse: 0.0047 - val_mae: 0.0532\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0457 - val_loss: 0.0046 - val_mse: 0.0046 - val_mae: 0.0540\n",
      "Epoch 24/50\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0483 - val_loss: 0.0156 - val_mse: 0.0156 - val_mae: 0.1058\n",
      "Epoch 25/50\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0423 - val_loss: 0.0075 - val_mse: 0.0075 - val_mae: 0.0694\n",
      "Epoch 26/50\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0417 - val_loss: 0.0076 - val_mse: 0.0076 - val_mae: 0.0719\n",
      "Epoch 27/50\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0414 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0621\n",
      "Epoch 28/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0413 - val_loss: 0.0098 - val_mse: 0.0098 - val_mae: 0.0794\n",
      "Epoch 29/50\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0410 - val_loss: 0.0061 - val_mse: 0.0061 - val_mae: 0.0626\n",
      "Epoch 30/50\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0438 - val_loss: 0.0120 - val_mse: 0.0120 - val_mae: 0.0933\n",
      "Epoch 31/50\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0422 - val_loss: 0.0132 - val_mse: 0.0132 - val_mae: 0.0969\n",
      "Epoch 32/50\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0439 - val_loss: 0.0115 - val_mse: 0.0115 - val_mae: 0.0859\n",
      "Epoch 33/50\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0421 - val_loss: 0.0168 - val_mse: 0.0168 - val_mae: 0.1057\n",
      "Epoch 34/50\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0411 - val_loss: 0.0083 - val_mse: 0.0083 - val_mae: 0.0741\n",
      "Epoch 35/50\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0386 - val_loss: 0.0089 - val_mse: 0.0089 - val_mae: 0.0766\n",
      "Epoch 36/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0410 - val_loss: 0.0116 - val_mse: 0.0116 - val_mae: 0.0906\n",
      "Epoch 37/50\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0406 - val_loss: 0.0041 - val_mse: 0.0041 - val_mae: 0.0498\n",
      "Epoch 38/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0416 - val_loss: 0.0084 - val_mse: 0.0084 - val_mae: 0.0736\n",
      "Epoch 39/50\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0416 - val_loss: 0.0113 - val_mse: 0.0113 - val_mae: 0.0883\n",
      "Epoch 40/50\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0376 - val_loss: 0.0091 - val_mse: 0.0091 - val_mae: 0.0753\n",
      "Epoch 41/50\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0387 - val_loss: 0.0059 - val_mse: 0.0059 - val_mae: 0.0595\n",
      "Epoch 42/50\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0378 - val_loss: 0.0074 - val_mse: 0.0074 - val_mae: 0.0691\n",
      "Epoch 43/50\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0382 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0613\n",
      "Epoch 44/50\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0403 - val_loss: 0.0097 - val_mse: 0.0097 - val_mae: 0.0801\n",
      "Epoch 45/50\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0392 - val_loss: 0.0093 - val_mse: 0.0093 - val_mae: 0.0769\n",
      "Epoch 46/50\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0399 - val_loss: 0.0068 - val_mse: 0.0068 - val_mae: 0.0641\n",
      "Epoch 47/50\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0441 - val_loss: 0.0069 - val_mse: 0.0069 - val_mae: 0.0641\n",
      "Epoch 48/50\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0375 - val_loss: 0.0105 - val_mse: 0.0105 - val_mae: 0.0797\n",
      "Epoch 49/50\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0392 - val_loss: 0.0048 - val_mse: 0.0048 - val_mae: 0.0519\n",
      "Epoch 50/50\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0371 - val_loss: 0.0088 - val_mse: 0.0088 - val_mae: 0.0744\n",
      "Model saved at 'xgb/nasdaq_cnn-lstm_model_with_xgb.h5'\n",
      "8/8 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# CNN-LSTM Training\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(2))\n",
    "# Don't need flatten\n",
    "\n",
    "model.add(LSTM(50, activation='relu', return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='Adam', metrics=['mse', 'mae'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=16)\n",
    "\n",
    "model.save('xgb/nasdaq_cnn-lstm_model_with_xgb.h5')\n",
    "print(\"Model saved at 'xgb/nasdaq_cnn-lstm_model_with_xgb.h5'\")\n",
    "\n",
    "# Prediction\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_copies_array = np.repeat(y_pred, X_train.shape[2], axis=-1) # the length of feature and target\n",
    "y_pred_inversed = scaler.inverse_transform(y_pred_copies_array)[:, 0]\n",
    "\n",
    "y_test_copies_array = np.repeat(y_test.reshape(-1, 1), X_train.shape[2], axis=-1)\n",
    "y_test_inversed = scaler.inverse_transform(y_test_copies_array)[:,0]\n",
    "\n",
    "# Convert y_pred_inversed to a dataframe and save as a csv file\n",
    "results_df = pd.DataFrame({'test': y_test_inversed,'lstm': y_pred_inversed})\n",
    "results_df.to_csv('xgb/nasdaq_cnn-lstm_predictions_with_xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02e2d79b-2434-4486-b6e3-d437a23927dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 30, 32)            3936      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 30, 32)            0         \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 32)                6336      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,305\n",
      "Trainable params: 10,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "50/50 [==============================] - 3s 17ms/step - loss: 0.0487 - mse: 0.0487 - mae: 0.1820 - val_loss: 0.0235 - val_mse: 0.0235 - val_mae: 0.1239\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0499 - val_loss: 0.0164 - val_mse: 0.0164 - val_mae: 0.0996\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0428 - val_loss: 0.0175 - val_mse: 0.0175 - val_mae: 0.1032\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0416 - val_loss: 0.0163 - val_mse: 0.0163 - val_mae: 0.0993\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0388 - val_loss: 0.0187 - val_mse: 0.0187 - val_mae: 0.1077\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0379 - val_loss: 0.0156 - val_mse: 0.0156 - val_mae: 0.0966\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0376 - val_loss: 0.0176 - val_mse: 0.0176 - val_mae: 0.1034\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0362 - val_loss: 0.0145 - val_mse: 0.0145 - val_mae: 0.0930\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0342 - val_loss: 0.0157 - val_mse: 0.0157 - val_mae: 0.0959\n",
      "Epoch 10/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0360 - val_loss: 0.0179 - val_mse: 0.0179 - val_mae: 0.1056\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0363 - val_loss: 0.0152 - val_mse: 0.0152 - val_mae: 0.0938\n",
      "Epoch 12/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0328 - val_loss: 0.0134 - val_mse: 0.0134 - val_mae: 0.0899\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0343 - val_loss: 0.0146 - val_mse: 0.0146 - val_mae: 0.0914\n",
      "Epoch 14/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0326 - val_loss: 0.0134 - val_mse: 0.0134 - val_mae: 0.0881\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0335 - val_loss: 0.0130 - val_mse: 0.0130 - val_mae: 0.0861\n",
      "Epoch 16/50\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.0018 - mse: 0.0018 - mae: 0.0333 - val_loss: 0.0128 - val_mse: 0.0128 - val_mae: 0.0843\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0314 - val_loss: 0.0131 - val_mse: 0.0131 - val_mae: 0.0852\n",
      "Epoch 18/50\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0309 - val_loss: 0.0127 - val_mse: 0.0127 - val_mae: 0.0829\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0290 - val_loss: 0.0122 - val_mse: 0.0122 - val_mae: 0.0814\n",
      "Epoch 20/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0282 - val_loss: 0.0118 - val_mse: 0.0118 - val_mae: 0.0794\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0291 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0741\n",
      "Epoch 22/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0293 - val_loss: 0.0118 - val_mse: 0.0118 - val_mae: 0.0790\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0281 - val_loss: 0.0114 - val_mse: 0.0114 - val_mae: 0.0767\n",
      "Epoch 24/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0294 - val_loss: 0.0116 - val_mse: 0.0116 - val_mae: 0.0777\n",
      "Epoch 25/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0277 - val_loss: 0.0116 - val_mse: 0.0116 - val_mae: 0.0784\n",
      "Epoch 26/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0297 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0728\n",
      "Epoch 27/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0286 - val_loss: 0.0128 - val_mse: 0.0128 - val_mae: 0.0870\n",
      "Epoch 28/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0299 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0782\n",
      "Epoch 29/50\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0304 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0755\n",
      "Epoch 30/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0268 - val_loss: 0.0115 - val_mse: 0.0115 - val_mae: 0.0785\n",
      "Epoch 31/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0014 - mse: 0.0014 - mae: 0.0290 - val_loss: 0.0111 - val_mse: 0.0111 - val_mae: 0.0749\n",
      "Epoch 32/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0278 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0738\n",
      "Epoch 33/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0280 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0728\n",
      "Epoch 34/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0274 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0725\n",
      "Epoch 35/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0278 - val_loss: 0.0130 - val_mse: 0.0130 - val_mae: 0.0901\n",
      "Epoch 36/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0016 - mse: 0.0016 - mae: 0.0314 - val_loss: 0.0105 - val_mse: 0.0105 - val_mae: 0.0728\n",
      "Epoch 37/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0269 - val_loss: 0.0118 - val_mse: 0.0118 - val_mae: 0.0810\n",
      "Epoch 38/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0263 - val_loss: 0.0103 - val_mse: 0.0103 - val_mae: 0.0704\n",
      "Epoch 39/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0260 - val_loss: 0.0113 - val_mse: 0.0113 - val_mae: 0.0777\n",
      "Epoch 40/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0261 - val_loss: 0.0104 - val_mse: 0.0104 - val_mae: 0.0708\n",
      "Epoch 41/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0267 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0752\n",
      "Epoch 42/50\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0253 - val_loss: 0.0100 - val_mse: 0.0100 - val_mae: 0.0679\n",
      "Epoch 43/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0250 - val_loss: 0.0100 - val_mse: 0.0100 - val_mae: 0.0679\n",
      "Epoch 44/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0272 - val_loss: 0.0101 - val_mse: 0.0101 - val_mae: 0.0694\n",
      "Epoch 45/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0269 - val_loss: 0.0101 - val_mse: 0.0101 - val_mae: 0.0690\n",
      "Epoch 46/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0257 - val_loss: 0.0097 - val_mse: 0.0097 - val_mae: 0.0660\n",
      "Epoch 47/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0264 - val_loss: 0.0105 - val_mse: 0.0105 - val_mae: 0.0737\n",
      "Epoch 48/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0261 - val_loss: 0.0098 - val_mse: 0.0098 - val_mae: 0.0672\n",
      "Epoch 49/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0249 - val_loss: 0.0097 - val_mse: 0.0097 - val_mae: 0.0704\n",
      "Epoch 50/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0012 - mse: 0.0012 - mae: 0.0271 - val_loss: 0.0099 - val_mse: 0.0099 - val_mae: 0.0679\n",
      "Model saved at 'xgb/nasdaq_gru_model_with_xgb.h5'\n",
      "8/8 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# GRU Training\n",
    "model = Sequential()\n",
    "model.add(GRU(units=32, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GRU(units=32))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='Adam', metrics=['mse', 'mae'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=16)\n",
    "\n",
    "model.save('xgb/nasdaq_gru_model_with_xgb.h5')\n",
    "print(\"Model saved at 'xgb/nasdaq_gru_model_with_xgb.h5'\")\n",
    "\n",
    "# Prediction\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_copies_array = np.repeat(y_pred, X_train.shape[2], axis=-1) # the length of feature and target\n",
    "y_pred_inversed = scaler.inverse_transform(y_pred_copies_array)[:, 0]\n",
    "\n",
    "y_test_copies_array = np.repeat(y_test.reshape(-1, 1), X_train.shape[2], axis=-1)\n",
    "y_test_inversed = scaler.inverse_transform(y_test_copies_array)[:,0]\n",
    "\n",
    "# Convert y_pred_inversed to a dataframe and save as a csv file\n",
    "results_df = pd.DataFrame({'test': y_test_inversed,'lstm': y_pred_inversed})\n",
    "results_df.to_csv('xgb/nasdaq_gru_predictions_with_xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "164ffa75-d6fd-4230-bc5b-2a0f7864f0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sru_2 (SRU)                 (None, 30, 32)            3040      \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 30, 32)            0         \n",
      "                                                                 \n",
      " sru_3 (SRU)                 (None, 32)                6240      \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,313\n",
      "Trainable params: 9,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "50/50 [==============================] - 7s 88ms/step - loss: 0.0522 - mse: 0.0522 - mae: 0.1570 - val_loss: 0.0038 - val_mse: 0.0038 - val_mae: 0.0559\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 4s 88ms/step - loss: 0.0152 - mse: 0.0152 - mae: 0.0870 - val_loss: 5.4976e-04 - val_mse: 5.4976e-04 - val_mae: 0.0183\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 4s 88ms/step - loss: 0.0086 - mse: 0.0086 - mae: 0.0668 - val_loss: 7.4099e-04 - val_mse: 7.4099e-04 - val_mae: 0.0203\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 4s 88ms/step - loss: 0.0087 - mse: 0.0087 - mae: 0.0674 - val_loss: 7.2753e-04 - val_mse: 7.2753e-04 - val_mae: 0.0200\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 4s 81ms/step - loss: 0.0076 - mse: 0.0076 - mae: 0.0621 - val_loss: 7.1268e-04 - val_mse: 7.1268e-04 - val_mae: 0.0222\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 5s 94ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0569 - val_loss: 0.0032 - val_mse: 0.0032 - val_mae: 0.0515\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 4s 86ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0553 - val_loss: 7.6580e-04 - val_mse: 7.6580e-04 - val_mae: 0.0231\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 5s 91ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0546 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0270\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 4s 85ms/step - loss: 0.0057 - mse: 0.0057 - mae: 0.0533 - val_loss: 0.0028 - val_mse: 0.0028 - val_mae: 0.0476\n",
      "Epoch 10/50\n",
      "50/50 [==============================] - 4s 87ms/step - loss: 0.0054 - mse: 0.0054 - mae: 0.0513 - val_loss: 6.3905e-04 - val_mse: 6.3905e-04 - val_mae: 0.0189\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 4s 87ms/step - loss: 0.0053 - mse: 0.0053 - mae: 0.0529 - val_loss: 0.0053 - val_mse: 0.0053 - val_mae: 0.0674\n",
      "Epoch 12/50\n",
      "50/50 [==============================] - 4s 82ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0480 - val_loss: 0.0015 - val_mse: 0.0015 - val_mae: 0.0332\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 4s 84ms/step - loss: 0.0052 - mse: 0.0052 - mae: 0.0510 - val_loss: 8.1938e-04 - val_mse: 8.1938e-04 - val_mae: 0.0237\n",
      "Epoch 14/50\n",
      "50/50 [==============================] - 4s 83ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0470 - val_loss: 0.0023 - val_mse: 0.0023 - val_mae: 0.0417\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 5s 91ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0479 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0266\n",
      "Epoch 16/50\n",
      "50/50 [==============================] - 4s 84ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0487 - val_loss: 7.1933e-04 - val_mse: 7.1933e-04 - val_mae: 0.0219\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 4s 89ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0461 - val_loss: 0.0017 - val_mse: 0.0017 - val_mae: 0.0358\n",
      "Epoch 18/50\n",
      "50/50 [==============================] - 4s 81ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0462 - val_loss: 5.8084e-04 - val_mse: 5.8084e-04 - val_mae: 0.0188\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 4s 87ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0440 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0304\n",
      "Epoch 20/50\n",
      "50/50 [==============================] - 5s 91ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0435 - val_loss: 7.4030e-04 - val_mse: 7.4030e-04 - val_mae: 0.0223\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - 4s 89ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0418 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0281\n",
      "Epoch 22/50\n",
      "50/50 [==============================] - 4s 89ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0421 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0292\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - 4s 85ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0453 - val_loss: 7.9529e-04 - val_mse: 7.9529e-04 - val_mae: 0.0222\n",
      "Epoch 24/50\n",
      "50/50 [==============================] - 5s 91ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0428 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0748\n",
      "Epoch 25/50\n",
      "50/50 [==============================] - 4s 88ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0438 - val_loss: 8.5564e-04 - val_mse: 8.5564e-04 - val_mae: 0.0228\n",
      "Epoch 26/50\n",
      "50/50 [==============================] - 4s 85ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0389 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0312\n",
      "Epoch 27/50\n",
      "50/50 [==============================] - 4s 84ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0426 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0533\n",
      "Epoch 28/50\n",
      "50/50 [==============================] - 4s 86ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0419 - val_loss: 5.8018e-04 - val_mse: 5.8018e-04 - val_mae: 0.0188\n",
      "Epoch 29/50\n",
      "50/50 [==============================] - 4s 89ms/step - loss: 0.0030 - mse: 0.0030 - mae: 0.0387 - val_loss: 0.0015 - val_mse: 0.0015 - val_mae: 0.0329\n",
      "Epoch 30/50\n",
      "50/50 [==============================] - 4s 87ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0432 - val_loss: 7.1455e-04 - val_mse: 7.1455e-04 - val_mae: 0.0210\n",
      "Epoch 31/50\n",
      "50/50 [==============================] - 5s 91ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0404 - val_loss: 0.0015 - val_mse: 0.0015 - val_mae: 0.0320\n",
      "Epoch 32/50\n",
      "50/50 [==============================] - 4s 87ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0377 - val_loss: 0.0024 - val_mse: 0.0024 - val_mae: 0.0411\n",
      "Epoch 33/50\n",
      "50/50 [==============================] - 4s 88ms/step - loss: 0.0031 - mse: 0.0031 - mae: 0.0397 - val_loss: 7.6965e-04 - val_mse: 7.6965e-04 - val_mae: 0.0219\n",
      "Epoch 34/50\n",
      "50/50 [==============================] - 4s 89ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0374 - val_loss: 9.4837e-04 - val_mse: 9.4837e-04 - val_mae: 0.0243\n",
      "Epoch 35/50\n",
      "50/50 [==============================] - 4s 88ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0376 - val_loss: 9.6958e-04 - val_mse: 9.6958e-04 - val_mae: 0.0252\n",
      "Epoch 36/50\n",
      "50/50 [==============================] - 4s 87ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0386 - val_loss: 7.6933e-04 - val_mse: 7.6933e-04 - val_mae: 0.0221\n",
      "Epoch 37/50\n",
      "50/50 [==============================] - 4s 84ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0348 - val_loss: 5.6796e-04 - val_mse: 5.6796e-04 - val_mae: 0.0186\n",
      "Epoch 38/50\n",
      "50/50 [==============================] - 4s 84ms/step - loss: 0.0027 - mse: 0.0027 - mae: 0.0369 - val_loss: 6.8915e-04 - val_mse: 6.8915e-04 - val_mae: 0.0209\n",
      "Epoch 39/50\n",
      "50/50 [==============================] - 4s 88ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0360 - val_loss: 5.8699e-04 - val_mse: 5.8699e-04 - val_mae: 0.0190\n",
      "Epoch 40/50\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0379 - val_loss: 0.0015 - val_mse: 0.0015 - val_mae: 0.0320\n",
      "Epoch 41/50\n",
      "50/50 [==============================] - 4s 88ms/step - loss: 0.0028 - mse: 0.0028 - mae: 0.0377 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0533\n",
      "Epoch 42/50\n",
      "50/50 [==============================] - 4s 88ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0350 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0276\n",
      "Epoch 43/50\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0354 - val_loss: 0.0017 - val_mse: 0.0017 - val_mae: 0.0343\n",
      "Epoch 44/50\n",
      "50/50 [==============================] - 4s 89ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0349 - val_loss: 0.0030 - val_mse: 0.0030 - val_mae: 0.0484\n",
      "Epoch 45/50\n",
      "50/50 [==============================] - 4s 83ms/step - loss: 0.0023 - mse: 0.0023 - mae: 0.0345 - val_loss: 0.0013 - val_mse: 0.0013 - val_mae: 0.0282\n",
      "Epoch 46/50\n",
      "50/50 [==============================] - 4s 89ms/step - loss: 0.0025 - mse: 0.0025 - mae: 0.0347 - val_loss: 7.1662e-04 - val_mse: 7.1662e-04 - val_mae: 0.0212\n",
      "Epoch 47/50\n",
      "50/50 [==============================] - 4s 90ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0349 - val_loss: 0.0051 - val_mse: 0.0051 - val_mae: 0.0650\n",
      "Epoch 48/50\n",
      "50/50 [==============================] - 4s 89ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0354 - val_loss: 0.0018 - val_mse: 0.0018 - val_mae: 0.0337\n",
      "Epoch 49/50\n",
      "50/50 [==============================] - 4s 89ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0356 - val_loss: 8.2841e-04 - val_mse: 8.2841e-04 - val_mae: 0.0225\n",
      "Epoch 50/50\n",
      "50/50 [==============================] - 5s 91ms/step - loss: 0.0022 - mse: 0.0022 - mae: 0.0337 - val_loss: 0.0018 - val_mse: 0.0018 - val_mae: 0.0335\n",
      "Model saved at 'xgb/nasdaq_sru_model_with_xgb.h5'\n",
      "8/8 [==============================] - 0s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "# SRU Training\n",
    "model = Sequential()\n",
    "\n",
    "model.add(SRU(units=32, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(SRU(units=32))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mse', 'mae'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=16)\n",
    "\n",
    "model.save('xgb/nasdaq_sru_model_with_xgb.h5')\n",
    "print(\"Model saved at 'xgb/nasdaq_sru_model_with_xgb.h5'\")\n",
    "\n",
    "# Prediction\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_copies_array = np.repeat(y_pred, X_train.shape[2], axis=-1) # the length of feature and target\n",
    "y_pred_inversed = scaler.inverse_transform(y_pred_copies_array)[:, 0]\n",
    "\n",
    "y_test_copies_array = np.repeat(y_test.reshape(-1, 1), X_train.shape[2], axis=-1)\n",
    "y_test_inversed = scaler.inverse_transform(y_test_copies_array)[:,0]\n",
    "\n",
    "# Convert y_pred_inversed to a dataframe and save as a csv file\n",
    "results_df = pd.DataFrame({'test': y_test_inversed,'lstm': y_pred_inversed})\n",
    "results_df.to_csv('xgb/nasdaq_sru_predictions_with_xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6474b6-533f-4fec-9c06-285b447530de",
   "metadata": {},
   "source": [
    "### Computing MSE & MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3ece9d5b-db1d-466e-9db3-711e1b5e6459",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_prediction_without_xgb = pd.read_csv('xgb/nasdaq_lstm_predictions_without_xgb.csv')\n",
    "lstm_prediction_with_xgb = pd.read_csv('xgb/nasdaq_lstm_predictions_with_xgb.csv')\n",
    "\n",
    "bi_lstm_prediction_without_xgb = pd.read_csv('xgb/nasdaq_bi-lstm_predictions_without_xgb.csv')\n",
    "bi_lstm_prediction_with_xgb = pd.read_csv('xgb/nasdaq_bi-lstm_predictions_with_xgb.csv')\n",
    "\n",
    "cnn_lstm_prediction_without_xgb = pd.read_csv('xgb/nasdaq_cnn-lstm_predictions_without_xgb.csv')\n",
    "cnn_lstm_prediction_with_xgb = pd.read_csv('xgb/nasdaq_cnn-lstm_predictions_with_xgb.csv')\n",
    "\n",
    "gru_prediction_without_xgb = pd.read_csv('xgb/nasdaq_gru_predictions_without_xgb.csv')\n",
    "gru_prediction_with_xgb = pd.read_csv('xgb/nasdaq_gru_predictions_with_xgb.csv')\n",
    "\n",
    "sru_prediction_without_xgb = pd.read_csv('xgb/nasdaq_sru_predictions_without_xgb.csv')\n",
    "sru_prediction_with_xgb = pd.read_csv('xgb/nasdaq_sru_predictions_with_xgb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "211a7b6d-3dbf-4bf3-a447-2d874cf2bb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nasdaq_prediction = pd.DataFrame({\n",
    "    'test': lstm_prediction_without_xgb.iloc[:, 0],  \n",
    "    'lstm': lstm_prediction_without_xgb.iloc[:, 1],  \n",
    "    'bi_lstm': bi_lstm_prediction_without_xgb.iloc[:, 1],  \n",
    "    'cnn_lstm': cnn_lstm_prediction_without_xgb.iloc[:, 1],  \n",
    "    'gru': gru_prediction_without_xgb.iloc[:, 1], \n",
    "    'sru': sru_prediction_without_xgb.iloc[:, 1],\n",
    "    'lstm_xgb': lstm_prediction_with_xgb.iloc[:, 1],  \n",
    "    'bi_lstm_xgb': bi_lstm_prediction_with_xgb.iloc[:, 1],  \n",
    "    'cnn_lstm_xgb': cnn_lstm_prediction_with_xgb.iloc[:, 1],  \n",
    "    'gru_xgb': gru_prediction_with_xgb.iloc[:, 1], \n",
    "    'sru_xgb': sru_prediction_with_xgb.iloc[:, 1],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3de8fc44-2be5-47e2-bd54-8c326a729592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>lstm</th>\n",
       "      <th>bi_lstm</th>\n",
       "      <th>cnn_lstm</th>\n",
       "      <th>gru</th>\n",
       "      <th>sru</th>\n",
       "      <th>lstm_xgb</th>\n",
       "      <th>bi_lstm_xgb</th>\n",
       "      <th>cnn_lstm_xgb</th>\n",
       "      <th>gru_xgb</th>\n",
       "      <th>sru_xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13988.809570</td>\n",
       "      <td>14107.323</td>\n",
       "      <td>13941.282</td>\n",
       "      <td>13961.976</td>\n",
       "      <td>14258.3530</td>\n",
       "      <td>13711.063</td>\n",
       "      <td>14221.403</td>\n",
       "      <td>14102.086</td>\n",
       "      <td>13489.424</td>\n",
       "      <td>13977.352</td>\n",
       "      <td>14007.865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13675.110352</td>\n",
       "      <td>14019.409</td>\n",
       "      <td>13889.750</td>\n",
       "      <td>14000.247</td>\n",
       "      <td>14154.0160</td>\n",
       "      <td>13596.746</td>\n",
       "      <td>14186.626</td>\n",
       "      <td>13999.069</td>\n",
       "      <td>13488.382</td>\n",
       "      <td>13862.408</td>\n",
       "      <td>13940.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13754.709961</td>\n",
       "      <td>13892.380</td>\n",
       "      <td>13791.889</td>\n",
       "      <td>13984.499</td>\n",
       "      <td>14004.1100</td>\n",
       "      <td>13468.923</td>\n",
       "      <td>14093.019</td>\n",
       "      <td>13870.125</td>\n",
       "      <td>13489.936</td>\n",
       "      <td>13724.401</td>\n",
       "      <td>13830.255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13884.030273</td>\n",
       "      <td>13850.838</td>\n",
       "      <td>13730.255</td>\n",
       "      <td>13994.648</td>\n",
       "      <td>13978.8955</td>\n",
       "      <td>13453.104</td>\n",
       "      <td>14017.961</td>\n",
       "      <td>13833.843</td>\n",
       "      <td>13479.063</td>\n",
       "      <td>13724.512</td>\n",
       "      <td>13797.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13858.940430</td>\n",
       "      <td>13912.508</td>\n",
       "      <td>13735.943</td>\n",
       "      <td>13972.160</td>\n",
       "      <td>14085.0630</td>\n",
       "      <td>13539.627</td>\n",
       "      <td>14008.428</td>\n",
       "      <td>13925.866</td>\n",
       "      <td>13476.957</td>\n",
       "      <td>13844.629</td>\n",
       "      <td>13839.830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           test       lstm    bi_lstm   cnn_lstm         gru        sru  \\\n",
       "0  13988.809570  14107.323  13941.282  13961.976  14258.3530  13711.063   \n",
       "1  13675.110352  14019.409  13889.750  14000.247  14154.0160  13596.746   \n",
       "2  13754.709961  13892.380  13791.889  13984.499  14004.1100  13468.923   \n",
       "3  13884.030273  13850.838  13730.255  13994.648  13978.8955  13453.104   \n",
       "4  13858.940430  13912.508  13735.943  13972.160  14085.0630  13539.627   \n",
       "\n",
       "    lstm_xgb  bi_lstm_xgb  cnn_lstm_xgb    gru_xgb    sru_xgb  \n",
       "0  14221.403    14102.086     13489.424  13977.352  14007.865  \n",
       "1  14186.626    13999.069     13488.382  13862.408  13940.479  \n",
       "2  14093.019    13870.125     13489.936  13724.401  13830.255  \n",
       "3  14017.961    13833.843     13479.063  13724.512  13797.300  \n",
       "4  14008.428    13925.866     13476.957  13844.629  13839.830  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nasdaq_prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0a74f24b-a60f-4d72-806d-8d76c6754214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Table:\n",
      "      Model       Base_MSE        XGB_MSE  MSE_Reduction(%)\n",
      "0      lstm  207192.327860   58634.452464         71.700471\n",
      "1   bi_lstm  171890.096922  113642.354201         33.886619\n",
      "2  cnn_lstm  960479.743859  885440.334473          7.812701\n",
      "3       gru  856956.070915  779493.083531          9.039318\n",
      "4       sru  514386.940667  134985.976806         73.757892\n",
      "\n",
      "MAE Table:\n",
      "      Model    Base_MAE     XGB_MAE  MAE_Reduction(%)\n",
      "0      lstm  350.849387  182.578073         47.961125\n",
      "1   bi_lstm  354.276523  241.144838         31.933159\n",
      "2  cnn_lstm  790.754204  813.547568         -2.882484\n",
      "3       gru  639.194311  587.845569          8.033354\n",
      "4       sru  647.902797  291.537070         55.002962\n"
     ]
    }
   ],
   "source": [
    "mse_results = {'Model': [], 'Base_MSE': [], 'XGB_MSE': [], 'MSE_Reduction(%)': []}\n",
    "mae_results = {'Model': [], 'Base_MAE': [], 'XGB_MAE': [], 'MAE_Reduction(%)': []}\n",
    "\n",
    "models = ['lstm', 'bi_lstm', 'cnn_lstm', 'gru', 'sru']\n",
    "\n",
    "for model in models:\n",
    "    base_mse = mean_squared_error(df_nasdaq_prediction['test'], df_nasdaq_prediction[model])\n",
    "    xgb_mse = mean_squared_error(df_nasdaq_prediction['test'], df_nasdaq_prediction[f\"{model}_xgb\"])\n",
    "    base_mae = mean_absolute_error(df_nasdaq_prediction['test'], df_nasdaq_prediction[model])\n",
    "    xgb_mae = mean_absolute_error(df_nasdaq_prediction['test'], df_nasdaq_prediction[f\"{model}_xgb\"])\n",
    "\n",
    "    mse_reduction = -((xgb_mse - base_mse) / base_mse) * 100\n",
    "    mae_reduction = -((xgb_mae - base_mae) / base_mae) * 100\n",
    "\n",
    "    mse_results['Model'].append(model)\n",
    "    mse_results['Base_MSE'].append(base_mse)\n",
    "    mse_results['XGB_MSE'].append(xgb_mse)\n",
    "    mse_results['MSE_Reduction(%)'].append(mse_reduction)\n",
    "    \n",
    "    mae_results['Model'].append(model)\n",
    "    mae_results['Base_MAE'].append(base_mae)\n",
    "    mae_results['XGB_MAE'].append(xgb_mae)\n",
    "    mae_results['MAE_Reduction(%)'].append(mae_reduction)\n",
    "\n",
    "mse_df = pd.DataFrame(mse_results)\n",
    "mae_df = pd.DataFrame(mae_results)\n",
    "\n",
    "print(\"MSE Table:\")\n",
    "print(mse_df)\n",
    "print(\"\\nMAE Table:\")\n",
    "print(mae_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
